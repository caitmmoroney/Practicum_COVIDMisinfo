@article{ribeiro_why_2016,
	title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
	url = {http://arxiv.org/abs/1602.04938},
	shorttitle = {"Why Should I Trust You?},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose {LIME}, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	journaltitle = {{arXiv}:1602.04938 [cs, stat]},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	urldate = {2020-11-19},
	date = {2016-08-09},
	eprinttype = {arxiv},
	eprint = {1602.04938},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/caitlinmoroney/Zotero/storage/P3ZYSE7B/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:application/pdf;arXiv.org Snapshot:/Users/caitlinmoroney/Zotero/storage/5RXGUYFV/1602.html:text/html}
}

@article{honkela_wordicaemergence_2010,
	title = {{WordICA}—emergence of linguistic representations for words by independent component analysis},
	volume = {16},
	issn = {1351-3249, 1469-8110},
	url = {https://www.cambridge.org/core/product/identifier/S1351324910000057/type/journal_article},
	doi = {10.1017/S1351324910000057},
	abstract = {Abstract
            We explore the use of independent component analysis ({ICA}) for the automatic extraction of linguistic roles or features of words. The extraction is based on the unsupervised analysis of text corpora. We contrast {ICA} with singular value decomposition ({SVD}), widely used in statistical text analysis, in general, and specifically in latent semantic analysis ({LSA}). However, the representations found using the {SVD} analysis cannot easily be interpreted by humans. In contrast, {ICA} applied on word context data gives distinct features which reflect linguistic categories. In this paper, we provide justification for our approach called {WordICA}, present the {WordICA} method in detail, compare the obtained results with traditional linguistic categories and with the results achieved using an {SVD}-based method, and discuss the use of the method in practical natural language engineering solutions such as machine translation systems. As the {WordICA} method is based on unsupervised learning and thus provides a general means for efficient knowledge acquisition, we foresee that the approach has a clear potential for practical applications.},
	pages = {277--308},
	number = {3},
	journaltitle = {Natural Language Engineering},
	shortjournal = {Nat. Lang. Eng.},
	author = {Honkela, Timo and Hyvärinen, Aapo and Väyrynen, Jaakko J.},
	urldate = {2020-11-29},
	date = {2010-07},
	langid = {english}
}

@inproceedings{levy_neural_2014,
	title = {Neural Word Embedding as Implicit Matrix Factorization},
	volume = {27},
	url = {https://proceedings.neurips.cc/paper/2014/file/feab05aa91085b7a8012516bc3533958-Paper.pdf},
	abstract = {We analyze skip-gram with negative-sampling (SGNS), a word embedding method introduced by Mikolov et al., and show that it is implicitly factorizing a word-context matrix, whose cells are the pointwise mutual information (PMI) of the respective word and context pairs, shifted by a global constant. We find that another embedding method, NCE, is implicitly factorizing a similar matrix, where each cell is the (shifted) log conditional probability of a word given its context. We show that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks. When dense low-dimensional vectors are preferred, exact factorization with SVD can achieve solutions that are at least as good as SGNS?s solutions for word similarity tasks. On analogy questions SGNS remains superior to SVD.We conjecture that this stems from the weighted nature of SGNS?s factorization.},
	pages = {2177--2185},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Levy, Omer and Goldberg, Yoav},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. and Weinberger, K. Q.},
	date = {2014}
}

@article{levy_improving_2015,
	title = {Improving Distributional Similarity with Lessons Learned from Word Embeddings},
	volume = {3},
	issn = {2307-387X},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00134},
	doi = {10.1162/tacl_a_00134},
	abstract = {Recent trends suggest that neural-network-inspired word embedding models outperform traditional count-based distributional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter optimizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others.},
	pages = {211--225},
	journaltitle = {Transactions of the Association for Computational Linguistics},
	shortjournal = {{TACL}},
	author = {Levy, Omer and Goldberg, Yoav and Dagan, Ido},
	urldate = {2020-11-29},
	date = {2015-12},
	langid = {english},
	file = {Full Text:/Users/caitlinmoroney/Zotero/storage/2HB9NYKJ/Levy et al. - 2015 - Improving Distributional Similarity with Lessons L.pdf:application/pdf}
	}