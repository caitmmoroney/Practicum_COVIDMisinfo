\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}

\title{Automated Detection of Misinformation in Tweets about COVID-19}

\author{
    Caitlin Moroney
    \thanks{Use footnote for providing further information about author (webpage,
alternative address)---\emph{not} for acknowledging funding agencies.
Optional.}
   \\
    Department of Mathematics and Statistics \\
    American University \\
  Washington, DC 20016 \\
  \texttt{\href{mailto:cm0246b@american.edu}{\nolinkurl{cm0246b@american.edu}}} \\
  }

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

% Pandoc citation processing

\begin{document}
\maketitle

\def\tightlist{}


\begin{abstract}
Enter the text of your abstract here.
\end{abstract}

\keywords{
    COVID-19
   \and
    coronavirus
   \and
    NLP
   \and
    machine learning
   \and
    misinformation
  }

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Insert introduction text here.

The rest of the paper is organized as follows: Section \ref{sec:methods}
discusses our methodology; Section \ref{sec:results} presents the
results of our experiments; Section \ref{sec:discuss} discusses our
results and plans for future work.

\hypertarget{methodology}{%
\section{Methodology}\label{methodology}}

\label{sec:methods} This paper explores a series of methods which seek
to exploit linguistic features in raw text data in order to perform the
automated detection of unreliable tweets. The experiments follow the
same general framework with certain implementation details tweaked for
each experiment. The first step in this framework is the application of
NLP featurization methods to the raw tweet text. While different
featurization methods are compared, all methods involve the use of NLP
tools to represent the text with numeric features. Subsequently, latent
variable methods are employed to reduce the dimensionality of the
resulting X feature matrix (as well as to uncover latent variables). The
latent variables are then used in the classification task. Finally, we
evaluate the classification algorithms paired with the featurization
methods with respect to performance and explainability. We use the
typical performance metrics, including accuracy, F-score, precision,
recall, and ROC-AUC. We use LIME to evaluate local explainability for
non-interpretable methods. Furthermore, we present a new explainability
framework for latent variable methods as well as a new explainability
metric. Below, we explore in greater detail the methods used for
featurization, latent variables, classification, and evaluation of
explainability.

\hypertarget{nlp-featurization}{%
\subsection{NLP featurization}\label{nlp-featurization}}

In order to obtain features from the raw tweet text, we first employed
standard preprocessing, to include removing stop words and punctuation
as well as lemmatizing words. The two approaches we pursued involved (1)
Bag-of-Words and (2) word embeddings, each followed by latent variable
methods.

\hypertarget{bag-of-words}{%
\subsubsection{Bag-of-Words}\label{bag-of-words}}

\begin{itemize}
\tightlist
\item
  Bag-of-Words + topic modeling

  \begin{itemize}
  \tightlist
  \item
    Vectorization: raw counts, tf-idf, binary
  \item
    PCA + ICA
  \end{itemize}
\end{itemize}

\hypertarget{word-embeddings}{%
\subsubsection{Word embeddings}\label{word-embeddings}}

\begin{itemize}
\tightlist
\item
  Word embeddings + topic modeling of word-context co-occurrence matrix

  \begin{itemize}
  \tightlist
  \item
    My embeddings

    \begin{itemize}
    \tightlist
    \item
      Laplace smoothing
    \item
      raw counts, PMI, PPMI
    \item
      PCA + ICA
    \end{itemize}
  \item
    BERT
  \end{itemize}
\end{itemize}

\hypertarget{latent-variable-methods}{%
\subsection{Latent variable methods}\label{latent-variable-methods}}

\begin{itemize}
\tightlist
\item
  Topic modeling
\item
  Word embeddings
\end{itemize}

\hypertarget{classification}{%
\subsection{Classification}\label{classification}}

\begin{itemize}
\tightlist
\item
  One-class SVM
\item
  Binary SVM
\end{itemize}

\hypertarget{evaluation}{%
\subsection{Evaluation}\label{evaluation}}

\begin{itemize}
\tightlist
\item
  Performance
\item
  Explainability

  \begin{itemize}
  \tightlist
  \item
    LIME (local)
  \item
    ICA

    \begin{itemize}
    \tightlist
    \item
      global
    \item
      local
    \end{itemize}
  \item
    Metric I came up with
  \end{itemize}
\end{itemize}

\hypertarget{results}{%
\section{Results}\label{results}}

\label{sec:results} Report evaluation metrics for\ldots{}

\begin{itemize}
\tightlist
\item
  One-class SVM
\item
  Binary SVM
\end{itemize}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

\label{sec:discuss}

\begin{itemize}
\tightlist
\item
  Interpret results
\item
  Future work

  \begin{itemize}
  \tightlist
  \item
    Better ICA explainability tool?
  \item
    Better explainability metric?
  \item
    Other classifiers (e.g., neural nets)
  \item
    Incorporate other features:

    \begin{itemize}
    \tightlist
    \item
      Part-of-speech tag counts
    \item
      Punctuation counts
    \item
      Use of all-caps
    \item
      Sentiment analysis
    \end{itemize}
  \end{itemize}
\end{itemize}

Misc. equation. \[
\xi _{ij}(t)=P(x_{t}=i,x_{t+1}=j|y,v,w;\theta)= {\frac {\alpha _{i}(t)a^{w_t}_{ij}\beta _{j}(t+1)b^{v_{t+1}}_{j}(y_{t+1})}{\sum _{i=1}^{N} \sum _{j=1}^{N} \alpha _{i}(t)a^{w_t}_{ij}\beta _{j}(t+1)b^{v_{t+1}}_{j}(y_{t+1})}}
\]

\paragraph{Paragraph}

Misc. text.

\hypertarget{examples-of-citations-figures-tables-references}{%
\section{Examples of citations, figures, tables,
references}\label{examples-of-citations-figures-tables-references}}

\label{sec:others}

\lipsum[8] some text (Kour and Saabne 2014b, 2014a) and see Hadash et
al. (2018).

The documentation for \verb+natbib+ may be found at

\begin{center}
  \url{http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf}
\end{center}

Of note is the command \verb+\citet+, which produces citations
appropriate for use in inline text. For example,

\begin{verbatim}
   \citet{hasselmo} investigated\dots
\end{verbatim}

produces

\begin{quote}
  Hasselmo, et al.\ (1995) investigated\dots
\end{quote}

\begin{center}
  \url{https://www.ctan.org/pkg/booktabs}
\end{center}

\hypertarget{figures}{%
\subsection{Figures}\label{figures}}

Misc. text. See Figure \ref{fig:fig1}. Here is how you add footnotes.
{[}\^{}Sample of the first footnote.{]}

\begin{figure}
  \centering
  \fbox{\rule[-.5cm]{4cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
  \caption{Sample figure caption.}
  \label{fig:fig1}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(mtcars}\OperatorTok{$}\NormalTok{mpg)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Moroney_FinalReport_files/figure-latex/unnamed-chunk-1-1.pdf}

\hypertarget{tables}{%
\subsection{Tables}\label{tables}}

Misc. text.

See awesome Table\textasciitilde{}\ref{tab:table}.

\begin{table}
 \caption{Sample table title}
  \centering
  \begin{tabular}{lll}
    \toprule
    \multicolumn{2}{c}{Part}                   \\
    \cmidrule(r){1-2}
    Name     & Description     & Size ($\mu$m) \\
    \midrule
    Dendrite & Input terminal  & $\sim$100     \\
    Axon     & Output terminal & $\sim$10      \\
    Soma     & Cell body       & up to $10^6$  \\
    \bottomrule
  \end{tabular}
  \label{tab:table}
\end{table}

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-hadash2018estimate}{}%
Hadash, Guy, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour, and
Alon Jacovi. 2018. ``Estimate and Replace: A Novel Approach to
Integrating Deep Neural Networks with Existing Applications.''
\emph{arXiv Preprint arXiv:1804.09028}.

\leavevmode\hypertarget{ref-kour2014fast}{}%
Kour, George, and Raid Saabne. 2014a. ``Fast Classification of
Handwritten on-Line Arabic Characters.'' In \emph{Soft Computing and
Pattern Recognition (Socpar), 2014 6th International Conference of},
312--18. IEEE.

\leavevmode\hypertarget{ref-kour2014real}{}%
---------. 2014b. ``Real-Time Segmentation of on-Line Handwritten Arabic
Script.'' In \emph{Frontiers in Handwriting Recognition (Icfhr), 2014
14th International Conference on}, 417--22. IEEE.

\bibliographystyle{unsrt}
\bibliography{references.bib}


\end{document}
