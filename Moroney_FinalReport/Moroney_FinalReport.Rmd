---
title: Automated Detection of Misinformation in Tweets about COVID-19
authors:
  - name: Caitlin Moroney
    thanks: Use footnote for providing further information about author (webpage, alternative address)---*not* for acknowledging funding agencies. Optional.
    department: Department of Mathematics and Statistics
    affiliation: American University
    location: Washington, DC 20016
    email: cm0246b@american.edu
abstract: |
  Enter the text of your abstract here.
keywords:
  - COVID-19
  - coronavirus
  - NLP
  - machine learning
  - misinformation
bibliography: references.bib
output: 
  rticles::arxiv_article:
    keep_tex: true
---

# Introduction

Insert introduction text here.

The rest of the paper is organized as follows: Section \ref{sec:methods} discusses our methodology; Section \ref{sec:results} presents the results of our experiments; Section \ref{sec:discuss} discusses our results and plans for future work.

# Methodology
\label{sec:methods}
This paper explores a series of methods which seek to exploit linguistic features in raw text data in order to perform the automated detection of unreliable tweets. The experiments follow the same general framework with certain implementation details tweaked for each experiment. The first step in this framework is the application of NLP featurization methods to the raw tweet text. While different featurization methods are compared, all methods involve the use of NLP tools to represent the text with numeric features. Subsequently, latent variable methods are employed to reduce the dimensionality of the resulting X feature matrix (as well as to uncover latent variables). The latent variables are then used in the classification task. Finally, we evaluate the classification algorithms paired with the featurization methods with respect to performance and explainability. We use the typical performance metrics, including accuracy, F-score, precision, recall, and ROC-AUC. We use LIME to evaluate local explainability for non-interpretable methods. Furthermore, we present a new explainability framework for latent variable methods as well as a new explainability metric. Below, we explore in greater detail the methods used for featurization, latent variables, classification, and evaluation of explainability.

## NLP featurization
In order to obtain features from the raw tweet text, we first employed standard preprocessing, to include removing stop words and punctuation as well as lemmatizing words. The two approaches we pursued involved (1) Bag-of-Words and (2) word embeddings, each followed by latent variable methods.

### Bag-of-Words
- Bag-of-Words + topic modeling
    - Vectorization: raw counts, tf-idf, binary
    - PCA + ICA

### Word embeddings
- Word embeddings + topic modeling of word-context co-occurrence matrix
    - My embeddings
        - Laplace smoothing
        - raw counts, PMI, PPMI
        - PCA + ICA
    - BERT

## Latent variable methods
- Topic modeling
- Word embeddings

## Classification
- One-class SVM
- Binary SVM

## Evaluation
- Performance
- Explainability
    - LIME (local)
    - ICA
        - global
        - local
    - Metric I came up with

# Results
\label{sec:results}
Report evaluation metrics for...

- One-class SVM
- Binary SVM

# Discussion
\label{sec:discuss}

- Interpret results
- Future work
    - Better ICA explainability tool?
    - Better explainability metric?
    - Other classifiers (e.g., neural nets)
    - Incorporate other features:
        - Part-of-speech tag counts
        - Punctuation counts
        - Use of all-caps
        - Sentiment analysis

Misc. equation.
$$
\xi _{ij}(t)=P(x_{t}=i,x_{t+1}=j|y,v,w;\theta)= {\frac {\alpha _{i}(t)a^{w_t}_{ij}\beta _{j}(t+1)b^{v_{t+1}}_{j}(y_{t+1})}{\sum _{i=1}^{N} \sum _{j=1}^{N} \alpha _{i}(t)a^{w_t}_{ij}\beta _{j}(t+1)b^{v_{t+1}}_{j}(y_{t+1})}}
$$

\paragraph{Paragraph}
Misc. text.

# Examples of citations, figures, tables, references
\label{sec:others}

\lipsum[8] some text [@kour2014real; @kour2014fast] and see @hadash2018estimate.

The documentation for \verb+natbib+ may be found at
\begin{center}
  \url{http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf}
\end{center}
Of note is the command \verb+\citet+, which produces citations
appropriate for use in inline text.  For example,

\begin{verbatim}
   \citet{hasselmo} investigated\dots
\end{verbatim}

produces

\begin{quote}
  Hasselmo, et al.\ (1995) investigated\dots
\end{quote}

\begin{center}
  \url{https://www.ctan.org/pkg/booktabs}
\end{center}

## Figures

Misc. text. 
See Figure \ref{fig:fig1}. Here is how you add footnotes. [^Sample of the first footnote.]

\begin{figure}
  \centering
  \fbox{\rule[-.5cm]{4cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
  \caption{Sample figure caption.}
  \label{fig:fig1}
\end{figure}

```{r}
plot(mtcars$mpg)
```

## Tables

Misc. text.

See awesome Table~\ref{tab:table}.

\begin{table}
 \caption{Sample table title}
  \centering
  \begin{tabular}{lll}
    \toprule
    \multicolumn{2}{c}{Part}                   \\
    \cmidrule(r){1-2}
    Name     & Description     & Size ($\mu$m) \\
    \midrule
    Dendrite & Input terminal  & $\sim$100     \\
    Axon     & Output terminal & $\sim$10      \\
    Soma     & Cell body       & up to $10^6$  \\
    \bottomrule
  \end{tabular}
  \label{tab:table}
\end{table}

# References

