{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "#from sklearn.covariance import EllipticEnvelope\n",
    "#from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x104e41110>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create outlier target values\n",
    "outlier = []\n",
    "for i in tweets['Is_Unreliable']:\n",
    "    if i == 0:\n",
    "        i = 1\n",
    "    else:\n",
    "        i = -1\n",
    "    outlier.append(i)\n",
    "tweets['outlier_target'] = outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>outlier_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus is spreading wild wide and cities ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This morning, Sunnybrook discharged home the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This afternoon, @WHO declared #coronavirus a p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese health authorities announced Sunday th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local communities band together to show their ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable Category  \\\n",
       "280              0      NaN   \n",
       "281              0      NaN   \n",
       "282              0      NaN   \n",
       "283              0      NaN   \n",
       "284              0      NaN   \n",
       "..             ...      ...   \n",
       "555              0      NaN   \n",
       "556              0      NaN   \n",
       "557              0      NaN   \n",
       "558              0      NaN   \n",
       "559              0      NaN   \n",
       "\n",
       "                                                 Tweet  outlier_target  \n",
       "280  Coronavirus is spreading wild wide and cities ...               1  \n",
       "281  This morning, Sunnybrook discharged home the p...               1  \n",
       "282  This afternoon, @WHO declared #coronavirus a p...               1  \n",
       "283  Chinese health authorities announced Sunday th...               1  \n",
       "284  Local communities band together to show their ...               1  \n",
       "..                                                 ...             ...  \n",
       "555  BREAKING: Harvard classes will move online sta...               1  \n",
       "556  Singularity University is hosting a FREE Virtu...               1  \n",
       "557  Coronavirus: how does it spread and what are t...               1  \n",
       "558  Stanford just cancelled classes for the rest o...               1  \n",
       "559  Tech conferences were cancelled in #Waterloo R...               1  \n",
       "\n",
       "[280 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reliable_tweets = tweets[tweets['outlier_target'] == 1]\n",
    "reliable_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, laplace_smoothing = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(reliable_tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yet</th>\n",
       "      <th>yokohama</th>\n",
       "      <th>york</th>\n",
       "      <th>yorku</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>2.697417</td>\n",
       "      <td>-0.277508</td>\n",
       "      <td>-0.357348</td>\n",
       "      <td>0.333142</td>\n",
       "      <td>0.071339</td>\n",
       "      <td>0.798775</td>\n",
       "      <td>-0.133872</td>\n",
       "      <td>0.683422</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>-0.141331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.120471</td>\n",
       "      <td>-0.118783</td>\n",
       "      <td>-0.225241</td>\n",
       "      <td>-0.122156</td>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.110301</td>\n",
       "      <td>-0.119628</td>\n",
       "      <td>-0.114551</td>\n",
       "      <td>1.583916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.277508</td>\n",
       "      <td>3.468590</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.708120</td>\n",
       "      <td>1.755651</td>\n",
       "      <td>0.968959</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>2.550056</td>\n",
       "      <td>-1.248726</td>\n",
       "      <td>-0.577283</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.244498</td>\n",
       "      <td>-1.249570</td>\n",
       "      <td>-1.247882</td>\n",
       "      <td>0.842885</td>\n",
       "      <td>-0.152642</td>\n",
       "      <td>-0.551351</td>\n",
       "      <td>-1.239400</td>\n",
       "      <td>-0.555579</td>\n",
       "      <td>-1.243650</td>\n",
       "      <td>1.504639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.357348</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.630939</td>\n",
       "      <td>2.707722</td>\n",
       "      <td>1.164986</td>\n",
       "      <td>-0.410163</td>\n",
       "      <td>-0.244197</td>\n",
       "      <td>0.727247</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.251657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.230797</td>\n",
       "      <td>-0.229109</td>\n",
       "      <td>-0.335567</td>\n",
       "      <td>-0.232482</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.220627</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>0.220827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.333142</td>\n",
       "      <td>0.708120</td>\n",
       "      <td>2.707722</td>\n",
       "      <td>0.625623</td>\n",
       "      <td>1.162328</td>\n",
       "      <td>-0.412821</td>\n",
       "      <td>-0.246855</td>\n",
       "      <td>0.724589</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.254315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.233455</td>\n",
       "      <td>-0.231767</td>\n",
       "      <td>-0.338225</td>\n",
       "      <td>-0.235140</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.223285</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.227535</td>\n",
       "      <td>0.218169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.071339</td>\n",
       "      <td>1.755651</td>\n",
       "      <td>1.164986</td>\n",
       "      <td>1.162328</td>\n",
       "      <td>2.042623</td>\n",
       "      <td>0.529349</td>\n",
       "      <td>0.472171</td>\n",
       "      <td>2.003232</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>0.177030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.900722</td>\n",
       "      <td>-0.205888</td>\n",
       "      <td>0.380802</td>\n",
       "      <td>0.196205</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.890553</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>-0.201656</td>\n",
       "      <td>1.160339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.551351</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.168214</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.283567</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>-0.009708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>-0.093618</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>-0.230372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>-0.110301</td>\n",
       "      <td>-1.239400</td>\n",
       "      <td>-0.220627</td>\n",
       "      <td>-0.223285</td>\n",
       "      <td>-0.890553</td>\n",
       "      <td>-0.163117</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-0.971617</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>-0.004611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>-0.088521</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>-0.225274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>-0.119628</td>\n",
       "      <td>-0.555579</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>-0.172443</td>\n",
       "      <td>-0.006477</td>\n",
       "      <td>-0.287795</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>-0.013937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>-0.097847</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>-0.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.114551</td>\n",
       "      <td>-1.243650</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>-0.227535</td>\n",
       "      <td>-0.201656</td>\n",
       "      <td>-0.167367</td>\n",
       "      <td>-0.001401</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>-0.008861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.013687</td>\n",
       "      <td>-0.092771</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>0.463623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>1.583916</td>\n",
       "      <td>1.504639</td>\n",
       "      <td>0.220827</td>\n",
       "      <td>0.218169</td>\n",
       "      <td>1.160339</td>\n",
       "      <td>0.683803</td>\n",
       "      <td>-0.248844</td>\n",
       "      <td>1.341640</td>\n",
       "      <td>0.864012</td>\n",
       "      <td>-0.256304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868241</td>\n",
       "      <td>-0.235443</td>\n",
       "      <td>-0.233756</td>\n",
       "      <td>-0.340214</td>\n",
       "      <td>-0.237128</td>\n",
       "      <td>-0.230372</td>\n",
       "      <td>-0.225274</td>\n",
       "      <td>-0.234600</td>\n",
       "      <td>0.463623</td>\n",
       "      <td>1.132471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 1164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   !         #         (         )         ,         -  \\\n",
       "!           2.697417 -0.277508 -0.357348  0.333142  0.071339  0.798775   \n",
       "#          -0.277508  3.468590  0.710778  0.708120  1.755651  0.968959   \n",
       "(          -0.357348  0.710778  0.630939  2.707722  1.164986 -0.410163   \n",
       ")           0.333142  0.708120  2.707722  0.625623  1.162328 -0.412821   \n",
       ",           0.071339  1.755651  1.164986  1.162328  2.042623  0.529349   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "zone       -0.115399 -0.551351 -0.225725 -0.228383 -0.202503 -0.168214   \n",
       "zuckerberg -0.110301 -1.239400 -0.220627 -0.223285 -0.890553 -0.163117   \n",
       "—          -0.119628 -0.555579 -0.229953 -0.232611 -0.206732 -0.172443   \n",
       "‘          -0.114551 -1.243650 -0.224877 -0.227535 -0.201656 -0.167367   \n",
       "’           1.583916  1.504639  0.220827  0.218169  1.160339  0.683803   \n",
       "\n",
       "                  --         .       ...         1  ...      yeah       yet  \\\n",
       "!          -0.133872  0.683422  1.266667 -0.141331  ... -0.115399 -0.120471   \n",
       "#           0.123324  2.550056 -1.248726 -0.577283  ... -1.244498 -1.249570   \n",
       "(          -0.244197  0.727247 -0.229953 -0.251657  ... -0.225725 -0.230797   \n",
       ")          -0.246855  0.724589 -0.232611 -0.254315  ... -0.228383 -0.233455   \n",
       ",           0.472171  2.003232 -0.206732  0.177030  ... -0.202503 -0.900722   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "zone       -0.002249 -0.283567  0.011995 -0.009708  ...  0.016224  0.011152   \n",
       "zuckerberg  0.002849 -0.971617  0.017093 -0.004611  ...  0.021321  0.016249   \n",
       "—          -0.006477 -0.287795  0.007767 -0.013937  ...  0.011995  0.006923   \n",
       "‘          -0.001401 -0.975866  0.012843 -0.008861  ...  0.017071  0.012000   \n",
       "’          -0.248844  1.341640  0.864012 -0.256304  ...  0.868241 -0.235443   \n",
       "\n",
       "            yokohama      york     yorku      zone  zuckerberg         —  \\\n",
       "!          -0.118783 -0.225241 -0.122156 -0.115399   -0.110301 -0.119628   \n",
       "#          -1.247882  0.842885 -0.152642 -0.551351   -1.239400 -0.555579   \n",
       "(          -0.229109 -0.335567 -0.232482 -0.225725   -0.220627 -0.229953   \n",
       ")          -0.231767 -0.338225 -0.235140 -0.228383   -0.223285 -0.232611   \n",
       ",          -0.205888  0.380802  0.196205 -0.202503   -0.890553 -0.206732   \n",
       "...              ...       ...       ...       ...         ...       ...   \n",
       "zone        0.012840 -0.093618  0.009467  0.016224    0.021321  0.011995   \n",
       "zuckerberg  0.017937 -0.088521  0.014565  0.021321    0.026419  0.017093   \n",
       "—           0.008611 -0.097847  0.005238  0.011995    0.017093  0.007767   \n",
       "‘           0.013687 -0.092771  0.010315  0.017071    0.022169  0.012843   \n",
       "’          -0.233756 -0.340214 -0.237128 -0.230372   -0.225274 -0.234600   \n",
       "\n",
       "                   ‘         ’  \n",
       "!          -0.114551  1.583916  \n",
       "#          -1.243650  1.504639  \n",
       "(          -0.224877  0.220827  \n",
       ")          -0.227535  0.218169  \n",
       ",          -0.201656  1.160339  \n",
       "...              ...       ...  \n",
       "zone        0.017071 -0.230372  \n",
       "zuckerberg  0.022169 -0.225274  \n",
       "—           0.012843 -0.234600  \n",
       "‘           0.017919  0.463623  \n",
       "’           0.463623  1.132471  \n",
       "\n",
       "[1164 rows x 1164 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164, 1164)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00412424, -0.03740951],\n",
       "       [ 0.85425724, -0.00332133],\n",
       "       [-0.0178243 , -0.0977268 ],\n",
       "       ...,\n",
       "       [ 0.00170812,  0.00628078],\n",
       "       [-0.0069683 ,  0.00572003],\n",
       "       [ 0.04388617, -0.06333264]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.004124</td>\n",
       "      <td>-0.037410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.854257</td>\n",
       "      <td>-0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.017824</td>\n",
       "      <td>-0.097727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-0.019524</td>\n",
       "      <td>-0.098920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.138477</td>\n",
       "      <td>-0.373170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>-0.001003</td>\n",
       "      <td>0.006876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>-0.003383</td>\n",
       "      <td>0.009097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.006281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.006968</td>\n",
       "      <td>0.005720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.043886</td>\n",
       "      <td>-0.063333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Comp 1    Comp 2\n",
       "!           0.004124 -0.037410\n",
       "#           0.854257 -0.003321\n",
       "(          -0.017824 -0.097727\n",
       ")          -0.019524 -0.098920\n",
       ",          -0.138477 -0.373170\n",
       "...              ...       ...\n",
       "zone       -0.001003  0.006876\n",
       "zuckerberg -0.003383  0.009097\n",
       "—           0.001708  0.006281\n",
       "‘          -0.006968  0.005720\n",
       "’           0.043886 -0.063333\n",
       "\n",
       "[1164 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07957104, -0.00170088,  0.02023189, ..., -0.00311904,\n",
       "        -0.00061618, -0.00312103],\n",
       "       [ 0.01171413,  0.00601497,  0.00828844, ...,  0.00353782,\n",
       "         0.00487398, -0.0026023 ],\n",
       "       [ 0.00586516,  0.00268852,  0.00933206, ..., -0.00439492,\n",
       "        -0.00555415,  0.0037854 ],\n",
       "       ...,\n",
       "       [ 0.00480271, -0.00210544, -0.00159936, ..., -0.01800727,\n",
       "        -0.00135372,  0.00128999],\n",
       "       [ 0.0066619 ,  0.00244455, -0.00882587, ..., -0.00117985,\n",
       "        -0.00012595, -0.00154651],\n",
       "       [-0.03572956,  0.01567932,  0.03090352, ...,  0.02585142,\n",
       "        -0.01894379,  0.0082209 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['outlier_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01249558, -0.00394117, -0.00156144, ...,  0.00787546,\n",
       "         0.0015077 ,  0.01018084],\n",
       "       [-0.00411777,  0.00082725, -0.00416658, ...,  0.00297394,\n",
       "         0.00039663, -0.0292302 ],\n",
       "       [ 0.00316146,  0.0042913 , -0.0027394 , ..., -0.00025228,\n",
       "        -0.00227752,  0.00503544],\n",
       "       ...,\n",
       "       [-0.00103255,  0.00050688,  0.09120201, ...,  0.00289042,\n",
       "         0.03015424,  0.00325381],\n",
       "       [ 0.00180065,  0.00052764, -0.00301714, ..., -0.00193796,\n",
       "        -0.00290247,  0.00250368],\n",
       "       [-0.00124305, -0.00958667,  0.03363261, ..., -0.00160618,\n",
       "        -0.00173168,  0.00129567]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_fraction = 0.20\n",
    "Nsamples_unreliable = int(np.round(280/(1-resample_fraction)*resample_fraction))\n",
    "\n",
    "resample_dict = {\n",
    "    -1: Nsamples_unreliable,\n",
    "    1: 280\n",
    "}\n",
    "\n",
    "underSample = RandomUnderSampler(sampling_strategy = resample_dict,\n",
    "                                 random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imb, y_imb = underSample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', OneClassSVM(nu = resample_fraction))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv, scoring = 'f1_macro')\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X_imb,\n",
    "                        y = y_imb,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1_macro', 'precision_macro', 'recall_macro'],\n",
    "                        return_estimator = True,\n",
    "                        return_train_score = True)\n",
    "\n",
    "test_auc = scores['test_roc_auc']\n",
    "train_auc = scores['train_roc_auc']\n",
    "\n",
    "test_accuracy = scores['test_accuracy']\n",
    "train_accuracy = scores['train_accuracy']\n",
    "\n",
    "test_f1 = scores['test_f1_macro']\n",
    "train_f1 = scores['train_f1_macro']\n",
    "\n",
    "test_precision = scores['test_precision_macro']\n",
    "train_precision = scores['train_precision_macro']\n",
    "\n",
    "test_recall = scores['test_recall_macro']\n",
    "train_recall = scores['train_recall_macro']\n",
    "\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28520408163265304"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6171428571428572"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4538224458869342"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45930893063557593"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4553571428571429"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
