{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "#from sklearn.covariance import EllipticEnvelope\n",
    "#from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a3727c290>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create outlier target values\n",
    "outlier = []\n",
    "for i in tweets['Is_Unreliable']:\n",
    "    if i == 0:\n",
    "        i = 1\n",
    "    else:\n",
    "        i = -1\n",
    "    outlier.append(i)\n",
    "tweets['outlier_target'] = outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>outlier_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus is spreading wild wide and cities ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This morning, Sunnybrook discharged home the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This afternoon, @WHO declared #coronavirus a p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese health authorities announced Sunday th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local communities band together to show their ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable Category  \\\n",
       "280              0      NaN   \n",
       "281              0      NaN   \n",
       "282              0      NaN   \n",
       "283              0      NaN   \n",
       "284              0      NaN   \n",
       "..             ...      ...   \n",
       "555              0      NaN   \n",
       "556              0      NaN   \n",
       "557              0      NaN   \n",
       "558              0      NaN   \n",
       "559              0      NaN   \n",
       "\n",
       "                                                 Tweet  outlier_target  \n",
       "280  Coronavirus is spreading wild wide and cities ...               1  \n",
       "281  This morning, Sunnybrook discharged home the p...               1  \n",
       "282  This afternoon, @WHO declared #coronavirus a p...               1  \n",
       "283  Chinese health authorities announced Sunday th...               1  \n",
       "284  Local communities band together to show their ...               1  \n",
       "..                                                 ...             ...  \n",
       "555  BREAKING: Harvard classes will move online sta...               1  \n",
       "556  Singularity University is hosting a FREE Virtu...               1  \n",
       "557  Coronavirus: how does it spread and what are t...               1  \n",
       "558  Stanford just cancelled classes for the rest o...               1  \n",
       "559  Tech conferences were cancelled in #Waterloo R...               1  \n",
       "\n",
       "[280 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reliable_tweets = tweets[tweets['outlier_target'] == 1]\n",
    "reliable_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, laplace_smoothing = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(reliable_tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yet</th>\n",
       "      <th>yokohama</th>\n",
       "      <th>york</th>\n",
       "      <th>yorku</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>2.697417</td>\n",
       "      <td>-0.277508</td>\n",
       "      <td>-0.357348</td>\n",
       "      <td>0.333142</td>\n",
       "      <td>0.071339</td>\n",
       "      <td>0.798775</td>\n",
       "      <td>-0.133872</td>\n",
       "      <td>0.683422</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>-0.141331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.120471</td>\n",
       "      <td>-0.118783</td>\n",
       "      <td>-0.225241</td>\n",
       "      <td>-0.122156</td>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.110301</td>\n",
       "      <td>-0.119628</td>\n",
       "      <td>-0.114551</td>\n",
       "      <td>1.583916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.277508</td>\n",
       "      <td>3.468590</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.708120</td>\n",
       "      <td>1.755651</td>\n",
       "      <td>0.968959</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>2.550056</td>\n",
       "      <td>-1.248726</td>\n",
       "      <td>-0.577283</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.244498</td>\n",
       "      <td>-1.249570</td>\n",
       "      <td>-1.247882</td>\n",
       "      <td>0.842885</td>\n",
       "      <td>-0.152642</td>\n",
       "      <td>-0.551351</td>\n",
       "      <td>-1.239400</td>\n",
       "      <td>-0.555579</td>\n",
       "      <td>-1.243650</td>\n",
       "      <td>1.504639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.357348</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.630939</td>\n",
       "      <td>2.707722</td>\n",
       "      <td>1.164986</td>\n",
       "      <td>-0.410163</td>\n",
       "      <td>-0.244197</td>\n",
       "      <td>0.727247</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.251657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.230797</td>\n",
       "      <td>-0.229109</td>\n",
       "      <td>-0.335567</td>\n",
       "      <td>-0.232482</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.220627</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>0.220827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.333142</td>\n",
       "      <td>0.708120</td>\n",
       "      <td>2.707722</td>\n",
       "      <td>0.625623</td>\n",
       "      <td>1.162328</td>\n",
       "      <td>-0.412821</td>\n",
       "      <td>-0.246855</td>\n",
       "      <td>0.724589</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.254315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.233455</td>\n",
       "      <td>-0.231767</td>\n",
       "      <td>-0.338225</td>\n",
       "      <td>-0.235140</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.223285</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.227535</td>\n",
       "      <td>0.218169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.071339</td>\n",
       "      <td>1.755651</td>\n",
       "      <td>1.164986</td>\n",
       "      <td>1.162328</td>\n",
       "      <td>2.042623</td>\n",
       "      <td>0.529349</td>\n",
       "      <td>0.472171</td>\n",
       "      <td>2.003232</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>0.177030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.900722</td>\n",
       "      <td>-0.205888</td>\n",
       "      <td>0.380802</td>\n",
       "      <td>0.196205</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.890553</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>-0.201656</td>\n",
       "      <td>1.160339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.551351</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.168214</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.283567</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>-0.009708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>-0.093618</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>-0.230372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>-0.110301</td>\n",
       "      <td>-1.239400</td>\n",
       "      <td>-0.220627</td>\n",
       "      <td>-0.223285</td>\n",
       "      <td>-0.890553</td>\n",
       "      <td>-0.163117</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-0.971617</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>-0.004611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>-0.088521</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>-0.225274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>-0.119628</td>\n",
       "      <td>-0.555579</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>-0.172443</td>\n",
       "      <td>-0.006477</td>\n",
       "      <td>-0.287795</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>-0.013937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>-0.097847</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>-0.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.114551</td>\n",
       "      <td>-1.243650</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>-0.227535</td>\n",
       "      <td>-0.201656</td>\n",
       "      <td>-0.167367</td>\n",
       "      <td>-0.001401</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>-0.008861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.013687</td>\n",
       "      <td>-0.092771</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>0.463623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>1.583916</td>\n",
       "      <td>1.504639</td>\n",
       "      <td>0.220827</td>\n",
       "      <td>0.218169</td>\n",
       "      <td>1.160339</td>\n",
       "      <td>0.683803</td>\n",
       "      <td>-0.248844</td>\n",
       "      <td>1.341640</td>\n",
       "      <td>0.864012</td>\n",
       "      <td>-0.256304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868241</td>\n",
       "      <td>-0.235443</td>\n",
       "      <td>-0.233756</td>\n",
       "      <td>-0.340214</td>\n",
       "      <td>-0.237128</td>\n",
       "      <td>-0.230372</td>\n",
       "      <td>-0.225274</td>\n",
       "      <td>-0.234600</td>\n",
       "      <td>0.463623</td>\n",
       "      <td>1.132471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 1164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   !         #         (         )         ,         -  \\\n",
       "!           2.697417 -0.277508 -0.357348  0.333142  0.071339  0.798775   \n",
       "#          -0.277508  3.468590  0.710778  0.708120  1.755651  0.968959   \n",
       "(          -0.357348  0.710778  0.630939  2.707722  1.164986 -0.410163   \n",
       ")           0.333142  0.708120  2.707722  0.625623  1.162328 -0.412821   \n",
       ",           0.071339  1.755651  1.164986  1.162328  2.042623  0.529349   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "zone       -0.115399 -0.551351 -0.225725 -0.228383 -0.202503 -0.168214   \n",
       "zuckerberg -0.110301 -1.239400 -0.220627 -0.223285 -0.890553 -0.163117   \n",
       "—          -0.119628 -0.555579 -0.229953 -0.232611 -0.206732 -0.172443   \n",
       "‘          -0.114551 -1.243650 -0.224877 -0.227535 -0.201656 -0.167367   \n",
       "’           1.583916  1.504639  0.220827  0.218169  1.160339  0.683803   \n",
       "\n",
       "                  --         .       ...         1  ...      yeah       yet  \\\n",
       "!          -0.133872  0.683422  1.266667 -0.141331  ... -0.115399 -0.120471   \n",
       "#           0.123324  2.550056 -1.248726 -0.577283  ... -1.244498 -1.249570   \n",
       "(          -0.244197  0.727247 -0.229953 -0.251657  ... -0.225725 -0.230797   \n",
       ")          -0.246855  0.724589 -0.232611 -0.254315  ... -0.228383 -0.233455   \n",
       ",           0.472171  2.003232 -0.206732  0.177030  ... -0.202503 -0.900722   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "zone       -0.002249 -0.283567  0.011995 -0.009708  ...  0.016224  0.011152   \n",
       "zuckerberg  0.002849 -0.971617  0.017093 -0.004611  ...  0.021321  0.016249   \n",
       "—          -0.006477 -0.287795  0.007767 -0.013937  ...  0.011995  0.006923   \n",
       "‘          -0.001401 -0.975866  0.012843 -0.008861  ...  0.017071  0.012000   \n",
       "’          -0.248844  1.341640  0.864012 -0.256304  ...  0.868241 -0.235443   \n",
       "\n",
       "            yokohama      york     yorku      zone  zuckerberg         —  \\\n",
       "!          -0.118783 -0.225241 -0.122156 -0.115399   -0.110301 -0.119628   \n",
       "#          -1.247882  0.842885 -0.152642 -0.551351   -1.239400 -0.555579   \n",
       "(          -0.229109 -0.335567 -0.232482 -0.225725   -0.220627 -0.229953   \n",
       ")          -0.231767 -0.338225 -0.235140 -0.228383   -0.223285 -0.232611   \n",
       ",          -0.205888  0.380802  0.196205 -0.202503   -0.890553 -0.206732   \n",
       "...              ...       ...       ...       ...         ...       ...   \n",
       "zone        0.012840 -0.093618  0.009467  0.016224    0.021321  0.011995   \n",
       "zuckerberg  0.017937 -0.088521  0.014565  0.021321    0.026419  0.017093   \n",
       "—           0.008611 -0.097847  0.005238  0.011995    0.017093  0.007767   \n",
       "‘           0.013687 -0.092771  0.010315  0.017071    0.022169  0.012843   \n",
       "’          -0.233756 -0.340214 -0.237128 -0.230372   -0.225274 -0.234600   \n",
       "\n",
       "                   ‘         ’  \n",
       "!          -0.114551  1.583916  \n",
       "#          -1.243650  1.504639  \n",
       "(          -0.224877  0.220827  \n",
       ")          -0.227535  0.218169  \n",
       ",          -0.201656  1.160339  \n",
       "...              ...       ...  \n",
       "zone        0.017071 -0.230372  \n",
       "zuckerberg  0.022169 -0.225274  \n",
       "—           0.012843 -0.234600  \n",
       "‘           0.017919  0.463623  \n",
       "’           0.463623  1.132471  \n",
       "\n",
       "[1164 rows x 1164 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164, 1164)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00542493,  0.03724313],\n",
       "       [ 0.85385444, -0.02643968],\n",
       "       [-0.01440906,  0.09828841],\n",
       "       ...,\n",
       "       [ 0.00148828, -0.00633647],\n",
       "       [-0.00716333, -0.00547381],\n",
       "       [ 0.0460658 ,  0.06176538]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.037243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.853854</td>\n",
       "      <td>-0.026440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.014409</td>\n",
       "      <td>0.098288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-0.016066</td>\n",
       "      <td>0.099540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.125393</td>\n",
       "      <td>0.377767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>-0.001242</td>\n",
       "      <td>-0.006837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>-0.003698</td>\n",
       "      <td>-0.008973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>0.001488</td>\n",
       "      <td>-0.006336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.007163</td>\n",
       "      <td>-0.005474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.046066</td>\n",
       "      <td>0.061765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Comp 1    Comp 2\n",
       "!           0.005425  0.037243\n",
       "#           0.853854 -0.026440\n",
       "(          -0.014409  0.098288\n",
       ")          -0.016066  0.099540\n",
       ",          -0.125393  0.377767\n",
       "...              ...       ...\n",
       "zone       -0.001242 -0.006837\n",
       "zuckerberg -0.003698 -0.008973\n",
       "—           0.001488 -0.006336\n",
       "‘          -0.007163 -0.005474\n",
       "’           0.046066  0.061765\n",
       "\n",
       "[1164 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01121837,  0.00982555,  0.01574539, ...,  0.00640451,\n",
       "         0.03120269, -0.06183339],\n",
       "       [ 0.00294059, -0.00624294,  0.00296914, ..., -0.00081244,\n",
       "        -0.00734716,  0.01017805],\n",
       "       [ 0.00222373,  0.00443057,  0.00091507, ...,  0.00274967,\n",
       "         0.00561379, -0.00809995],\n",
       "       ...,\n",
       "       [ 0.00533967,  0.00779238, -0.02362931, ...,  0.00874035,\n",
       "         0.00305804, -0.000991  ],\n",
       "       [ 0.00407724, -0.00169198, -0.00300804, ...,  0.00633921,\n",
       "         0.00618037, -0.00519585],\n",
       "       [ 0.0080058 ,  0.00506006,  0.01881806, ...,  0.00996156,\n",
       "         0.03296782, -0.10203954]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['outlier_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00212158,  0.00037287, -0.00220655, ...,  0.00623311,\n",
       "         0.01919314,  0.01071406],\n",
       "       [-0.00078167,  0.00200648, -0.00345922, ...,  0.00316014,\n",
       "         0.01421785, -0.00346045],\n",
       "       [ 0.00061564,  0.00288916, -0.00662823, ...,  0.00122059,\n",
       "        -0.0004905 , -0.00059413],\n",
       "       ...,\n",
       "       [ 0.00255065,  0.00359958,  0.00017891, ...,  0.00387632,\n",
       "         0.00278025, -0.01292087],\n",
       "       [ 0.00075879,  0.00573762, -0.00190593, ...,  0.00062826,\n",
       "         0.00106443,  0.00062992],\n",
       "       [ 0.00272393,  0.00049456, -0.00153424, ...,  0.00134907,\n",
       "         0.00415347, -0.00091346]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_fraction = 0.15\n",
    "Nsamples_unreliable = 280*resample_fraction\n",
    "\n",
    "resample_dict = {\n",
    "    -1: 42,\n",
    "    1: 280\n",
    "}\n",
    "\n",
    "underSample = RandomUnderSampler(sampling_strategy = resample_dict,\n",
    "                                 random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imb, y_imb = underSample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', OneClassSVM(nu = resample_fraction))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv, scoring = 'f1_macro')\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X_imb,\n",
    "                        y = y_imb,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1_macro', 'precision_macro', 'recall_macro'],\n",
    "                        return_estimator = True,\n",
    "                        return_train_score = True)\n",
    "\n",
    "test_auc = scores['test_roc_auc']\n",
    "train_auc = scores['train_roc_auc']\n",
    "\n",
    "test_accuracy = scores['test_accuracy']\n",
    "train_accuracy = scores['train_accuracy']\n",
    "\n",
    "test_f1 = scores['test_f1_macro']\n",
    "train_f1 = scores['train_f1_macro']\n",
    "\n",
    "test_precision = scores['test_precision_macro']\n",
    "train_precision = scores['train_precision_macro']\n",
    "\n",
    "test_recall = scores['test_recall_macro']\n",
    "train_recall = scores['train_recall_macro']\n",
    "\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2980654761904762"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6804807692307693"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45964376131165635"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4748154908643018"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46051587301587305"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
