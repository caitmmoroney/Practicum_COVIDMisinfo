{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "#from sklearn.covariance import EllipticEnvelope\n",
    "#from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x103668fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create outlier target values\n",
    "outlier = []\n",
    "for i in tweets['Is_Unreliable']:\n",
    "    if i == 0:\n",
    "        i = 1\n",
    "    else:\n",
    "        i = -1\n",
    "    outlier.append(i)\n",
    "tweets['outlier_target'] = outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>outlier_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus is spreading wild wide and cities ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This morning, Sunnybrook discharged home the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This afternoon, @WHO declared #coronavirus a p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese health authorities announced Sunday th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local communities band together to show their ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable Category  \\\n",
       "280              0      NaN   \n",
       "281              0      NaN   \n",
       "282              0      NaN   \n",
       "283              0      NaN   \n",
       "284              0      NaN   \n",
       "..             ...      ...   \n",
       "555              0      NaN   \n",
       "556              0      NaN   \n",
       "557              0      NaN   \n",
       "558              0      NaN   \n",
       "559              0      NaN   \n",
       "\n",
       "                                                 Tweet  outlier_target  \n",
       "280  Coronavirus is spreading wild wide and cities ...               1  \n",
       "281  This morning, Sunnybrook discharged home the p...               1  \n",
       "282  This afternoon, @WHO declared #coronavirus a p...               1  \n",
       "283  Chinese health authorities announced Sunday th...               1  \n",
       "284  Local communities band together to show their ...               1  \n",
       "..                                                 ...             ...  \n",
       "555  BREAKING: Harvard classes will move online sta...               1  \n",
       "556  Singularity University is hosting a FREE Virtu...               1  \n",
       "557  Coronavirus: how does it spread and what are t...               1  \n",
       "558  Stanford just cancelled classes for the rest o...               1  \n",
       "559  Tech conferences were cancelled in #Waterloo R...               1  \n",
       "\n",
       "[280 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reliable_tweets = tweets[tweets['outlier_target'] == 1]\n",
    "reliable_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, spmi_k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(reliable_tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yet</th>\n",
       "      <th>yokohama</th>\n",
       "      <th>york</th>\n",
       "      <th>yorku</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>1.879643</td>\n",
       "      <td>-3.119609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.644453</td>\n",
       "      <td>-2.594003</td>\n",
       "      <td>-0.654838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.808632</td>\n",
       "      <td>2.247368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-3.119609</td>\n",
       "      <td>-0.643522</td>\n",
       "      <td>-2.355308</td>\n",
       "      <td>-2.367039</td>\n",
       "      <td>-2.197358</td>\n",
       "      <td>-1.847428</td>\n",
       "      <td>-1.147723</td>\n",
       "      <td>-1.440974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.458897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.559746</td>\n",
       "      <td>-1.093656</td>\n",
       "      <td>-1.381338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.653272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.510749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.355308</td>\n",
       "      <td>-1.561568</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>-1.711919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.248304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.275154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-1.644453</td>\n",
       "      <td>-2.367039</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>-1.585029</td>\n",
       "      <td>-1.723650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.260034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.286885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-2.594003</td>\n",
       "      <td>-2.197358</td>\n",
       "      <td>-1.711919</td>\n",
       "      <td>-1.723650</td>\n",
       "      <td>-1.734931</td>\n",
       "      <td>-2.238113</td>\n",
       "      <td>-0.622118</td>\n",
       "      <td>-1.823290</td>\n",
       "      <td>-1.127666</td>\n",
       "      <td>-1.240144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.855732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.078876</td>\n",
       "      <td>-2.014969</td>\n",
       "      <td>-0.568050</td>\n",
       "      <td>-0.855732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.127666</td>\n",
       "      <td>-0.791194</td>\n",
       "      <td>-1.732358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.381338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.855732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.986652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.653272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.127666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.258586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.791194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.138599</td>\n",
       "      <td>-1.510749</td>\n",
       "      <td>-2.275154</td>\n",
       "      <td>-2.286885</td>\n",
       "      <td>-1.732358</td>\n",
       "      <td>-1.297271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.575595</td>\n",
       "      <td>1.199471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.471404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842796</td>\n",
       "      <td>-0.909299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 1164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   !         #         (         )         ,         -  \\\n",
       "!           1.879643 -3.119609  0.000000 -1.644453 -2.594003 -0.654838   \n",
       "#          -3.119609 -0.643522 -2.355308 -2.367039 -2.197358 -1.847428   \n",
       "(           0.000000 -2.355308 -1.561568  0.869048 -1.711919  0.000000   \n",
       ")          -1.644453 -2.367039  0.869048 -1.585029 -1.723650  0.000000   \n",
       ",          -2.594003 -2.197358 -1.711919 -1.723650 -1.734931 -2.238113   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "zone        0.000000 -1.381338  0.000000  0.000000 -0.855732  0.000000   \n",
       "zuckerberg  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "—           0.000000 -1.653272  0.000000  0.000000 -1.127666  0.000000   \n",
       "‘           0.000000  0.000000  0.000000  0.000000 -0.791194  0.000000   \n",
       "’           0.138599 -1.510749 -2.275154 -2.286885 -1.732358 -1.297271   \n",
       "\n",
       "                  --         .       ...         1  ...      yeah  yet  \\\n",
       "!           0.000000 -1.808632  2.247368  0.000000  ...  0.000000  0.0   \n",
       "#          -1.147723 -1.440974  0.000000 -2.458897  ...  0.000000  0.0   \n",
       "(           0.000000 -2.248304  0.000000  0.000000  ...  0.000000  0.0   \n",
       ")           0.000000 -2.260034  0.000000  0.000000  ...  0.000000  0.0   \n",
       ",          -0.622118 -1.823290 -1.127666 -1.240144  ... -0.855732  0.0   \n",
       "...              ...       ...       ...       ...  ...       ...  ...   \n",
       "zone        0.000000 -0.986652  0.000000  0.000000  ...  0.000000  0.0   \n",
       "zuckerberg  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.0   \n",
       "—           0.000000 -1.258586  0.000000  0.000000  ...  0.000000  0.0   \n",
       "‘           0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.0   \n",
       "’           0.000000 -1.575595  1.199471  0.000000  ...  1.471404  0.0   \n",
       "\n",
       "            yokohama      york     yorku      zone  zuckerberg         —  \\\n",
       "!           0.000000  0.000000  0.000000  0.000000         0.0  0.000000   \n",
       "#           0.000000 -1.559746 -1.093656 -1.381338         0.0 -1.653272   \n",
       "(           0.000000  0.000000  0.000000  0.000000         0.0  0.000000   \n",
       ")           0.000000  0.000000  0.000000  0.000000         0.0  0.000000   \n",
       ",          -1.078876 -2.014969 -0.568050 -0.855732         0.0 -1.127666   \n",
       "...              ...       ...       ...       ...         ...       ...   \n",
       "zone        0.000000  0.000000  0.000000  0.000000         0.0  0.000000   \n",
       "zuckerberg  0.000000  0.000000  0.000000  0.000000         0.0  0.000000   \n",
       "—           0.000000  0.000000  0.000000  0.000000         0.0  0.000000   \n",
       "‘           0.000000  0.000000  0.000000  0.000000         0.0  0.000000   \n",
       "’           0.000000  0.000000  0.000000  0.000000         0.0  0.000000   \n",
       "\n",
       "                   ‘         ’  \n",
       "!           0.000000  0.138599  \n",
       "#           0.000000 -1.510749  \n",
       "(           0.000000 -2.275154  \n",
       ")           0.000000 -2.286885  \n",
       ",          -0.791194 -1.732358  \n",
       "...              ...       ...  \n",
       "zone        0.000000  0.000000  \n",
       "zuckerberg  0.000000  0.000000  \n",
       "—           0.000000  0.000000  \n",
       "‘           0.000000  0.842796  \n",
       "’           0.842796 -0.909299  \n",
       "\n",
       "[1164 rows x 1164 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164, 1164)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03182626,  0.02004646],\n",
       "       [ 0.36232723, -0.14510057],\n",
       "       [ 0.10186631,  0.02926534],\n",
       "       ...,\n",
       "       [-0.01941838, -0.00041036],\n",
       "       [-0.00812901, -0.0017914 ],\n",
       "       [ 0.11419543,  0.03211276]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.031826</td>\n",
       "      <td>0.020046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.362327</td>\n",
       "      <td>-0.145101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.101866</td>\n",
       "      <td>0.029265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.104735</td>\n",
       "      <td>0.029669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.288938</td>\n",
       "      <td>-0.133740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>-0.014507</td>\n",
       "      <td>-0.003459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>-0.007076</td>\n",
       "      <td>-0.004806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>-0.019418</td>\n",
       "      <td>-0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.008129</td>\n",
       "      <td>-0.001791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.114195</td>\n",
       "      <td>0.032113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Comp 1    Comp 2\n",
       "!           0.031826  0.020046\n",
       "#           0.362327 -0.145101\n",
       "(           0.101866  0.029265\n",
       ")           0.104735  0.029669\n",
       ",           0.288938 -0.133740\n",
       "...              ...       ...\n",
       "zone       -0.014507 -0.003459\n",
       "zuckerberg -0.007076 -0.004806\n",
       "—          -0.019418 -0.000410\n",
       "‘          -0.008129 -0.001791\n",
       "’           0.114195  0.032113\n",
       "\n",
       "[1164 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.05924663e-03, -6.85422329e-02, -1.69655101e-03, ...,\n",
       "         1.64285159e-03,  2.76624184e-03,  6.26260910e-04],\n",
       "       [-4.42001273e-03,  2.95283723e-03,  2.02958929e-03, ...,\n",
       "         4.09429601e-03,  3.66930886e-02, -2.28948116e-02],\n",
       "       [-1.36515940e-02, -1.31091496e-01, -1.78210232e-03, ...,\n",
       "         1.28440974e-02, -7.16193548e-03,  1.25172312e-02],\n",
       "       ...,\n",
       "       [-2.51314281e-03, -4.61948866e-03,  2.21420919e-02, ...,\n",
       "        -3.68945667e-03,  1.63256792e-04, -1.15479780e-05],\n",
       "       [ 1.13816438e-03,  2.45662132e-03,  2.07275274e-03, ...,\n",
       "        -4.65446909e-03,  2.03077459e-03, -3.52181222e-01],\n",
       "       [ 1.74165395e-01, -7.58003159e-03, -1.90120289e-02, ...,\n",
       "        -7.79365358e-03, -6.21761162e-02, -5.15530004e-02]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['outlier_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01524536, -0.00788886, -0.00645728, ..., -0.00347787,\n",
       "        -0.00685556, -0.00319004],\n",
       "       [ 0.0002255 , -0.01228633,  0.00652833, ..., -0.0022675 ,\n",
       "         0.0036801 ,  0.00425808],\n",
       "       [ 0.00017882, -0.01150428,  0.00808833, ..., -0.0031305 ,\n",
       "         0.00431926,  0.0059167 ],\n",
       "       ...,\n",
       "       [ 0.00175685, -0.00775521, -0.00404828, ..., -0.00572999,\n",
       "        -0.00388559, -0.00453292],\n",
       "       [ 0.0029687 , -0.00762023,  0.00193704, ...,  0.00054623,\n",
       "         0.00174717,  0.00743948],\n",
       "       [ 0.00390057, -0.00218953,  0.00424206, ...,  0.00274528,\n",
       "        -0.0002521 ,  0.00210558]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_fraction = 0.15\n",
    "Nsamples_unreliable = 280*resample_fraction\n",
    "\n",
    "resample_dict = {\n",
    "    -1: 42,\n",
    "    1: 280\n",
    "}\n",
    "\n",
    "underSample = RandomUnderSampler(sampling_strategy = resample_dict,\n",
    "                                 random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imb, y_imb = underSample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', OneClassSVM(nu = resample_fraction))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv, scoring = 'f1_macro')\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X_imb,\n",
    "                        y = y_imb,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1_macro', 'precision_macro', 'recall_macro'],\n",
    "                        return_estimator = True,\n",
    "                        return_train_score = True)\n",
    "\n",
    "test_auc = scores['test_roc_auc']\n",
    "train_auc = scores['train_roc_auc']\n",
    "\n",
    "test_accuracy = scores['test_accuracy']\n",
    "train_accuracy = scores['train_accuracy']\n",
    "\n",
    "test_f1 = scores['test_f1_macro']\n",
    "train_f1 = scores['train_f1_macro']\n",
    "\n",
    "test_precision = scores['test_precision_macro']\n",
    "train_precision = scores['train_precision_macro']\n",
    "\n",
    "test_recall = scores['test_recall_macro']\n",
    "train_recall = scores['train_recall_macro']\n",
    "\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14990079365079367"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6866826923076923"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.405378332048806"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4190866307024691"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39464285714285713"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
