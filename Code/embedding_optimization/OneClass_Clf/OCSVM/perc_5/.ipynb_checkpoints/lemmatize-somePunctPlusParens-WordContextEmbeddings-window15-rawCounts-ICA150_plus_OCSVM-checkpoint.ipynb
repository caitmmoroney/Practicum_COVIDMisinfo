{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "#from sklearn.covariance import EllipticEnvelope\n",
    "#from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a18e90b90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create outlier target values\n",
    "outlier = []\n",
    "for i in tweets['Is_Unreliable']:\n",
    "    if i == 0:\n",
    "        i = 1\n",
    "    else:\n",
    "        i = -1\n",
    "    outlier.append(i)\n",
    "tweets['outlier_target'] = outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>outlier_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus is spreading wild wide and cities ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This morning, Sunnybrook discharged home the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This afternoon, @WHO declared #coronavirus a p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese health authorities announced Sunday th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local communities band together to show their ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable Category  \\\n",
       "280              0      NaN   \n",
       "281              0      NaN   \n",
       "282              0      NaN   \n",
       "283              0      NaN   \n",
       "284              0      NaN   \n",
       "..             ...      ...   \n",
       "555              0      NaN   \n",
       "556              0      NaN   \n",
       "557              0      NaN   \n",
       "558              0      NaN   \n",
       "559              0      NaN   \n",
       "\n",
       "                                                 Tweet  outlier_target  \n",
       "280  Coronavirus is spreading wild wide and cities ...               1  \n",
       "281  This morning, Sunnybrook discharged home the p...               1  \n",
       "282  This afternoon, @WHO declared #coronavirus a p...               1  \n",
       "283  Chinese health authorities announced Sunday th...               1  \n",
       "284  Local communities band together to show their ...               1  \n",
       "..                                                 ...             ...  \n",
       "555  BREAKING: Harvard classes will move online sta...               1  \n",
       "556  Singularity University is hosting a FREE Virtu...               1  \n",
       "557  Coronavirus: how does it spread and what are t...               1  \n",
       "558  Stanford just cancelled classes for the rest o...               1  \n",
       "559  Tech conferences were cancelled in #Waterloo R...               1  \n",
       "\n",
       "[280 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reliable_tweets = tweets[tweets['outlier_target'] == 1]\n",
    "reliable_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(reliable_tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yet</th>\n",
       "      <th>yokohama</th>\n",
       "      <th>york</th>\n",
       "      <th>yorku</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>2</td>\n",
       "      <td>392</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 1164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             !    #   (   )   ,   -  --    .  ...  1  ...  yeah  yet  \\\n",
       "!           18    2   0   1   2   2   0    5    3  0  ...     0    0   \n",
       "#            2  392   8   8  49  10   3  119    0  1  ...     0    0   \n",
       "(            0    8   2  23   9   0   0    6    0  0  ...     0    0   \n",
       ")            1    8  23   2   9   0   0    6    0  0  ...     0    0   \n",
       ",            2   49   9   9  46   4   3   48    1  2  ...     1    0   \n",
       "...         ..  ...  ..  ..  ..  ..  ..  ...  ... ..  ...   ...  ...   \n",
       "zone         0    1   0   0   1   0   0    1    0  0  ...     0    0   \n",
       "zuckerberg   0    0   0   0   0   0   0    0    0  0  ...     0    0   \n",
       "—            0    1   0   0   1   0   0    1    0  0  ...     0    0   \n",
       "‘            0    0   0   0   1   0   0    0    0  0  ...     0    0   \n",
       "’            6   19   1   1   9   2   0   12    2  0  ...     2    0   \n",
       "\n",
       "            yokohama  york  yorku  zone  zuckerberg  —  ‘   ’  \n",
       "!                  0     0      0     0           0  0  0   6  \n",
       "#                  0     8      2     1           0  1  0  19  \n",
       "(                  0     0      0     0           0  0  0   1  \n",
       ")                  0     0      0     0           0  0  0   1  \n",
       ",                  1     3      2     1           0  1  1   9  \n",
       "...              ...   ...    ...   ...         ... .. ..  ..  \n",
       "zone               0     0      0     0           0  0  0   0  \n",
       "zuckerberg         0     0      0     0           0  0  0   0  \n",
       "—                  0     0      0     0           0  0  0   0  \n",
       "‘                  0     0      0     0           0  0  0   1  \n",
       "’                  0     0      0     0           0  0  1   4  \n",
       "\n",
       "[1164 rows x 1164 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164, 1164)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01174607, -0.01933401],\n",
       "       [-0.92035565,  0.00544756],\n",
       "       [ 0.01605564, -0.03924997],\n",
       "       ...,\n",
       "       [-0.00134857,  0.00489965],\n",
       "       [ 0.00449222,  0.00287659],\n",
       "       [-0.02184362, -0.03007475]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.011746</td>\n",
       "      <td>-0.019334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.920356</td>\n",
       "      <td>0.005448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.016056</td>\n",
       "      <td>-0.039250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.017162</td>\n",
       "      <td>-0.040680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.095694</td>\n",
       "      <td>-0.281869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.005074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.004204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>-0.001349</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.002877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-0.021844</td>\n",
       "      <td>-0.030075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Comp 1    Comp 2\n",
       "!           0.011746 -0.019334\n",
       "#          -0.920356  0.005448\n",
       "(           0.016056 -0.039250\n",
       ")           0.017162 -0.040680\n",
       ",           0.095694 -0.281869\n",
       "...              ...       ...\n",
       "zone        0.000406  0.005074\n",
       "zuckerberg  0.003100  0.004204\n",
       "—          -0.001349  0.004900\n",
       "‘           0.004492  0.002877\n",
       "’          -0.021844 -0.030075\n",
       "\n",
       "[1164 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.68624526e-03,  3.68938662e-03, -8.85806387e-03, ...,\n",
       "         4.90958925e-03,  1.27926463e-02,  1.49799295e-03],\n",
       "       [ 2.06804784e-03,  4.23044671e-04,  2.09678316e-03, ...,\n",
       "        -2.70190881e-03, -1.84559256e-04, -4.43827890e-03],\n",
       "       [ 5.34347528e-03,  8.38343240e-03, -2.48035512e-03, ...,\n",
       "        -8.40586687e-03, -2.33698633e-02,  6.72348605e-03],\n",
       "       ...,\n",
       "       [-2.16737630e-02,  1.08550818e-03,  1.02898978e-03, ...,\n",
       "        -6.34260871e-03, -6.46410302e-03,  3.17142615e-03],\n",
       "       [ 3.11590539e-03, -3.65929165e-04,  2.68175862e-01, ...,\n",
       "         1.43161866e-03,  6.50972091e-04, -9.48935579e-03],\n",
       "       [ 7.42256120e-03,  7.33441007e-03,  1.47028052e-01, ...,\n",
       "        -1.63432427e-02, -1.52285196e-02, -1.39439050e-02]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['outlier_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00188709,  0.00897383,  0.00230834, ..., -0.00635864,\n",
       "         0.00508309, -0.00090732],\n",
       "       [-0.00196513, -0.00048285, -0.00422849, ...,  0.00781524,\n",
       "        -0.00476123,  0.00099583],\n",
       "       [-0.00095503, -0.00406118, -0.00230403, ..., -0.00082061,\n",
       "        -0.00044874, -0.00502792],\n",
       "       ...,\n",
       "       [ 0.00058028, -0.00270395,  0.00851846, ..., -0.00034854,\n",
       "         0.00314276, -0.00770541],\n",
       "       [ 0.00050876, -0.00057476, -0.00704814, ..., -0.00291631,\n",
       "         0.00217894,  0.20752007],\n",
       "       [-0.06889634, -0.00455761,  0.0045845 , ..., -0.00221698,\n",
       "        -0.05545661,  0.0068342 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_fraction = 0.05\n",
    "Nsamples_unreliable = int(np.round(280/(1-resample_fraction)*resample_fraction))\n",
    "\n",
    "resample_dict = {\n",
    "    -1: Nsamples_unreliable,\n",
    "    1: 280\n",
    "}\n",
    "\n",
    "underSample = RandomUnderSampler(sampling_strategy = resample_dict,\n",
    "                                 random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imb, y_imb = underSample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', OneClassSVM(nu = resample_fraction))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv, scoring = 'f1_macro')\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X_imb,\n",
    "                        y = y_imb,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1_macro', 'precision_macro', 'recall_macro'],\n",
    "                        return_estimator = True,\n",
    "                        return_train_score = True)\n",
    "\n",
    "test_auc = scores['test_roc_auc']\n",
    "train_auc = scores['train_roc_auc']\n",
    "\n",
    "test_accuracy = scores['test_accuracy']\n",
    "train_accuracy = scores['train_accuracy']\n",
    "\n",
    "test_f1 = scores['test_f1_macro']\n",
    "train_f1 = scores['train_f1_macro']\n",
    "\n",
    "test_precision = scores['test_precision_macro']\n",
    "train_precision = scores['train_precision_macro']\n",
    "\n",
    "test_recall = scores['test_recall_macro']\n",
    "train_recall = scores['train_recall_macro']\n",
    "\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17261904761904762"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7932203389830508"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44201529231847225"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4697986527418439"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41785714285714287"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
