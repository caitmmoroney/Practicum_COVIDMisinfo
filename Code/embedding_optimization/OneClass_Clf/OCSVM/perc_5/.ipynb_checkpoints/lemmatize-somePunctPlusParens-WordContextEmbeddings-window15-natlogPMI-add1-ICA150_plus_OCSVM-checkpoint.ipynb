{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "#from sklearn.covariance import EllipticEnvelope\n",
    "#from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a22ee4190>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create outlier target values\n",
    "outlier = []\n",
    "for i in tweets['Is_Unreliable']:\n",
    "    if i == 0:\n",
    "        i = 1\n",
    "    else:\n",
    "        i = -1\n",
    "    outlier.append(i)\n",
    "tweets['outlier_target'] = outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>outlier_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus is spreading wild wide and cities ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This morning, Sunnybrook discharged home the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This afternoon, @WHO declared #coronavirus a p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese health authorities announced Sunday th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local communities band together to show their ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable Category  \\\n",
       "280              0      NaN   \n",
       "281              0      NaN   \n",
       "282              0      NaN   \n",
       "283              0      NaN   \n",
       "284              0      NaN   \n",
       "..             ...      ...   \n",
       "555              0      NaN   \n",
       "556              0      NaN   \n",
       "557              0      NaN   \n",
       "558              0      NaN   \n",
       "559              0      NaN   \n",
       "\n",
       "                                                 Tweet  outlier_target  \n",
       "280  Coronavirus is spreading wild wide and cities ...               1  \n",
       "281  This morning, Sunnybrook discharged home the p...               1  \n",
       "282  This afternoon, @WHO declared #coronavirus a p...               1  \n",
       "283  Chinese health authorities announced Sunday th...               1  \n",
       "284  Local communities band together to show their ...               1  \n",
       "..                                                 ...             ...  \n",
       "555  BREAKING: Harvard classes will move online sta...               1  \n",
       "556  Singularity University is hosting a FREE Virtu...               1  \n",
       "557  Coronavirus: how does it spread and what are t...               1  \n",
       "558  Stanford just cancelled classes for the rest o...               1  \n",
       "559  Tech conferences were cancelled in #Waterloo R...               1  \n",
       "\n",
       "[280 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reliable_tweets = tweets[tweets['outlier_target'] == 1]\n",
    "reliable_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, laplace_smoothing = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(reliable_tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yet</th>\n",
       "      <th>yokohama</th>\n",
       "      <th>york</th>\n",
       "      <th>yorku</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>2.697417</td>\n",
       "      <td>-0.277508</td>\n",
       "      <td>-0.357348</td>\n",
       "      <td>0.333142</td>\n",
       "      <td>0.071339</td>\n",
       "      <td>0.798775</td>\n",
       "      <td>-0.133872</td>\n",
       "      <td>0.683422</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>-0.141331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.120471</td>\n",
       "      <td>-0.118783</td>\n",
       "      <td>-0.225241</td>\n",
       "      <td>-0.122156</td>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.110301</td>\n",
       "      <td>-0.119628</td>\n",
       "      <td>-0.114551</td>\n",
       "      <td>1.583916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.277508</td>\n",
       "      <td>3.468590</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.708120</td>\n",
       "      <td>1.755651</td>\n",
       "      <td>0.968959</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>2.550056</td>\n",
       "      <td>-1.248726</td>\n",
       "      <td>-0.577283</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.244498</td>\n",
       "      <td>-1.249570</td>\n",
       "      <td>-1.247882</td>\n",
       "      <td>0.842885</td>\n",
       "      <td>-0.152642</td>\n",
       "      <td>-0.551351</td>\n",
       "      <td>-1.239400</td>\n",
       "      <td>-0.555579</td>\n",
       "      <td>-1.243650</td>\n",
       "      <td>1.504639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.357348</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.630939</td>\n",
       "      <td>2.707722</td>\n",
       "      <td>1.164986</td>\n",
       "      <td>-0.410163</td>\n",
       "      <td>-0.244197</td>\n",
       "      <td>0.727247</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.251657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.230797</td>\n",
       "      <td>-0.229109</td>\n",
       "      <td>-0.335567</td>\n",
       "      <td>-0.232482</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.220627</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>0.220827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.333142</td>\n",
       "      <td>0.708120</td>\n",
       "      <td>2.707722</td>\n",
       "      <td>0.625623</td>\n",
       "      <td>1.162328</td>\n",
       "      <td>-0.412821</td>\n",
       "      <td>-0.246855</td>\n",
       "      <td>0.724589</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.254315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.233455</td>\n",
       "      <td>-0.231767</td>\n",
       "      <td>-0.338225</td>\n",
       "      <td>-0.235140</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.223285</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.227535</td>\n",
       "      <td>0.218169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.071339</td>\n",
       "      <td>1.755651</td>\n",
       "      <td>1.164986</td>\n",
       "      <td>1.162328</td>\n",
       "      <td>2.042623</td>\n",
       "      <td>0.529349</td>\n",
       "      <td>0.472171</td>\n",
       "      <td>2.003232</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>0.177030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.900722</td>\n",
       "      <td>-0.205888</td>\n",
       "      <td>0.380802</td>\n",
       "      <td>0.196205</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.890553</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>-0.201656</td>\n",
       "      <td>1.160339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.551351</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.168214</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.283567</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>-0.009708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>-0.093618</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>-0.230372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>-0.110301</td>\n",
       "      <td>-1.239400</td>\n",
       "      <td>-0.220627</td>\n",
       "      <td>-0.223285</td>\n",
       "      <td>-0.890553</td>\n",
       "      <td>-0.163117</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-0.971617</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>-0.004611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>-0.088521</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>-0.225274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>-0.119628</td>\n",
       "      <td>-0.555579</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>-0.172443</td>\n",
       "      <td>-0.006477</td>\n",
       "      <td>-0.287795</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>-0.013937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>-0.097847</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>-0.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.114551</td>\n",
       "      <td>-1.243650</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>-0.227535</td>\n",
       "      <td>-0.201656</td>\n",
       "      <td>-0.167367</td>\n",
       "      <td>-0.001401</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>-0.008861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.013687</td>\n",
       "      <td>-0.092771</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>0.463623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>1.583916</td>\n",
       "      <td>1.504639</td>\n",
       "      <td>0.220827</td>\n",
       "      <td>0.218169</td>\n",
       "      <td>1.160339</td>\n",
       "      <td>0.683803</td>\n",
       "      <td>-0.248844</td>\n",
       "      <td>1.341640</td>\n",
       "      <td>0.864012</td>\n",
       "      <td>-0.256304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868241</td>\n",
       "      <td>-0.235443</td>\n",
       "      <td>-0.233756</td>\n",
       "      <td>-0.340214</td>\n",
       "      <td>-0.237128</td>\n",
       "      <td>-0.230372</td>\n",
       "      <td>-0.225274</td>\n",
       "      <td>-0.234600</td>\n",
       "      <td>0.463623</td>\n",
       "      <td>1.132471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 1164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   !         #         (         )         ,         -  \\\n",
       "!           2.697417 -0.277508 -0.357348  0.333142  0.071339  0.798775   \n",
       "#          -0.277508  3.468590  0.710778  0.708120  1.755651  0.968959   \n",
       "(          -0.357348  0.710778  0.630939  2.707722  1.164986 -0.410163   \n",
       ")           0.333142  0.708120  2.707722  0.625623  1.162328 -0.412821   \n",
       ",           0.071339  1.755651  1.164986  1.162328  2.042623  0.529349   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "zone       -0.115399 -0.551351 -0.225725 -0.228383 -0.202503 -0.168214   \n",
       "zuckerberg -0.110301 -1.239400 -0.220627 -0.223285 -0.890553 -0.163117   \n",
       "—          -0.119628 -0.555579 -0.229953 -0.232611 -0.206732 -0.172443   \n",
       "‘          -0.114551 -1.243650 -0.224877 -0.227535 -0.201656 -0.167367   \n",
       "’           1.583916  1.504639  0.220827  0.218169  1.160339  0.683803   \n",
       "\n",
       "                  --         .       ...         1  ...      yeah       yet  \\\n",
       "!          -0.133872  0.683422  1.266667 -0.141331  ... -0.115399 -0.120471   \n",
       "#           0.123324  2.550056 -1.248726 -0.577283  ... -1.244498 -1.249570   \n",
       "(          -0.244197  0.727247 -0.229953 -0.251657  ... -0.225725 -0.230797   \n",
       ")          -0.246855  0.724589 -0.232611 -0.254315  ... -0.228383 -0.233455   \n",
       ",           0.472171  2.003232 -0.206732  0.177030  ... -0.202503 -0.900722   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "zone       -0.002249 -0.283567  0.011995 -0.009708  ...  0.016224  0.011152   \n",
       "zuckerberg  0.002849 -0.971617  0.017093 -0.004611  ...  0.021321  0.016249   \n",
       "—          -0.006477 -0.287795  0.007767 -0.013937  ...  0.011995  0.006923   \n",
       "‘          -0.001401 -0.975866  0.012843 -0.008861  ...  0.017071  0.012000   \n",
       "’          -0.248844  1.341640  0.864012 -0.256304  ...  0.868241 -0.235443   \n",
       "\n",
       "            yokohama      york     yorku      zone  zuckerberg         —  \\\n",
       "!          -0.118783 -0.225241 -0.122156 -0.115399   -0.110301 -0.119628   \n",
       "#          -1.247882  0.842885 -0.152642 -0.551351   -1.239400 -0.555579   \n",
       "(          -0.229109 -0.335567 -0.232482 -0.225725   -0.220627 -0.229953   \n",
       ")          -0.231767 -0.338225 -0.235140 -0.228383   -0.223285 -0.232611   \n",
       ",          -0.205888  0.380802  0.196205 -0.202503   -0.890553 -0.206732   \n",
       "...              ...       ...       ...       ...         ...       ...   \n",
       "zone        0.012840 -0.093618  0.009467  0.016224    0.021321  0.011995   \n",
       "zuckerberg  0.017937 -0.088521  0.014565  0.021321    0.026419  0.017093   \n",
       "—           0.008611 -0.097847  0.005238  0.011995    0.017093  0.007767   \n",
       "‘           0.013687 -0.092771  0.010315  0.017071    0.022169  0.012843   \n",
       "’          -0.233756 -0.340214 -0.237128 -0.230372   -0.225274 -0.234600   \n",
       "\n",
       "                   ‘         ’  \n",
       "!          -0.114551  1.583916  \n",
       "#          -1.243650  1.504639  \n",
       "(          -0.224877  0.220827  \n",
       ")          -0.227535  0.218169  \n",
       ",          -0.201656  1.160339  \n",
       "...              ...       ...  \n",
       "zone        0.017071 -0.230372  \n",
       "zuckerberg  0.022169 -0.225274  \n",
       "—           0.012843 -0.234600  \n",
       "‘           0.017919  0.463623  \n",
       "’           0.463623  1.132471  \n",
       "\n",
       "[1164 rows x 1164 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164, 1164)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01951733,  0.03218003],\n",
       "       [-0.67544867,  0.52300628],\n",
       "       [ 0.07366607,  0.0666449 ],\n",
       "       ...,\n",
       "       [-0.00518057, -0.00394049],\n",
       "       [ 0.00204187, -0.00878104],\n",
       "       [ 0.0037751 ,  0.07695953]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.019517</td>\n",
       "      <td>0.032180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.675449</td>\n",
       "      <td>0.523006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>0.073666</td>\n",
       "      <td>0.066645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.075741</td>\n",
       "      <td>0.066555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.337137</td>\n",
       "      <td>0.211590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>-0.003393</td>\n",
       "      <td>-0.006064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>-0.002858</td>\n",
       "      <td>-0.009275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>-0.005181</td>\n",
       "      <td>-0.003940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>0.002042</td>\n",
       "      <td>-0.008781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.076960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Comp 1    Comp 2\n",
       "!           0.019517  0.032180\n",
       "#          -0.675449  0.523006\n",
       "(           0.073666  0.066645\n",
       ")           0.075741  0.066555\n",
       ",           0.337137  0.211590\n",
       "...              ...       ...\n",
       "zone       -0.003393 -0.006064\n",
       "zuckerberg -0.002858 -0.009275\n",
       "—          -0.005181 -0.003940\n",
       "‘           0.002042 -0.008781\n",
       "’           0.003775  0.076960\n",
       "\n",
       "[1164 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00427395,  0.01307188, -0.01176301, ..., -0.00049241,\n",
       "         0.00092554, -0.00879476],\n",
       "       [ 0.00791967,  0.00096834,  0.00461801, ..., -0.00267861,\n",
       "        -0.00497647, -0.00425952],\n",
       "       [ 0.00067345,  0.00393523,  0.00580206, ...,  0.00413834,\n",
       "         0.00597725,  0.00665231],\n",
       "       ...,\n",
       "       [-0.01612372, -0.00765602,  0.00399236, ..., -0.00019648,\n",
       "         0.00052374, -0.00677281],\n",
       "       [-0.00068925, -0.00886074,  0.00389373, ..., -0.00232684,\n",
       "        -0.00055628,  0.00614679],\n",
       "       [ 0.00743974,  0.00959342,  0.00802285, ...,  0.00199972,\n",
       "         0.0151004 ,  0.01865776]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['outlier_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.95856345e-02, -1.28903881e-03,  2.62169052e-03, ...,\n",
       "         9.02035135e-03, -2.15047805e-03,  9.94553835e-02],\n",
       "       [-4.96348315e-03, -1.67676633e-03, -1.97645909e-03, ...,\n",
       "        -2.98843337e-02, -7.26957011e-04,  8.29311733e-02],\n",
       "       [ 3.34662625e-02, -6.13699942e-04, -5.41134733e-04, ...,\n",
       "         5.45770949e-03,  2.31159726e-03,  1.07277248e-01],\n",
       "       ...,\n",
       "       [-2.53764080e-03, -7.11339610e-05,  2.18094405e-03, ...,\n",
       "         2.72386311e-03, -3.02539627e-02,  9.20242814e-02],\n",
       "       [-5.14017124e-03, -1.67545497e-03,  2.59406989e-03, ...,\n",
       "         2.95396834e-03,  2.95475633e-03,  7.63931861e-02],\n",
       "       [-9.28834487e-04,  1.58015647e-03,  5.49668249e-03, ...,\n",
       "         1.49974285e-03,  1.63516152e-03,  3.14946675e-02]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_fraction = 0.05\n",
    "Nsamples_unreliable = int(np.round(280/(1-resample_fraction)*resample_fraction))\n",
    "\n",
    "resample_dict = {\n",
    "    -1: Nsamples_unreliable,\n",
    "    1: 280\n",
    "}\n",
    "\n",
    "underSample = RandomUnderSampler(sampling_strategy = resample_dict,\n",
    "                                 random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imb, y_imb = underSample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', OneClassSVM(nu = resample_fraction))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv, scoring = 'f1_macro')\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X_imb,\n",
    "                        y = y_imb,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1_macro', 'precision_macro', 'recall_macro'],\n",
    "                        return_estimator = True,\n",
    "                        return_train_score = True)\n",
    "\n",
    "test_auc = scores['test_roc_auc']\n",
    "train_auc = scores['train_roc_auc']\n",
    "\n",
    "test_accuracy = scores['test_accuracy']\n",
    "train_accuracy = scores['train_accuracy']\n",
    "\n",
    "test_f1 = scores['test_f1_macro']\n",
    "train_f1 = scores['train_f1_macro']\n",
    "\n",
    "test_precision = scores['test_precision_macro']\n",
    "train_precision = scores['train_precision_macro']\n",
    "\n",
    "test_recall = scores['test_recall_macro']\n",
    "train_recall = scores['train_recall_macro']\n",
    "\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20357142857142857"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8033898305084746"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45525844464831183"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47839999831235025"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45476190476190476"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
