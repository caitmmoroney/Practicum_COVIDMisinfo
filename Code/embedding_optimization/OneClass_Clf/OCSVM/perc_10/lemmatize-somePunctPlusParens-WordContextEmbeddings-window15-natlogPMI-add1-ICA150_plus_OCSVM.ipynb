{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Context Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "#from sklearn.covariance import EllipticEnvelope\n",
    "#from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert contractions picked up by word_tokenize() into full words\n",
    "contractions = {\n",
    "    \"n't\": 'not',\n",
    "    \"'ve\": 'have',\n",
    "    \"'s\": 'is', # note that this will include possessive nouns\n",
    "    'gonna': 'going to',\n",
    "    'gotta': 'got to',\n",
    "    \"'d\": 'would',\n",
    "    \"'ll\": 'will',\n",
    "    \"'re\": 'are',\n",
    "    \"'m\": 'am',\n",
    "    'wanna': 'want to'\n",
    "}\n",
    "\n",
    "# to convert nltk_pos tags to wordnet-compatible PoS tags\n",
    "def convert_pos_wordnet(tag):\n",
    "    tag_abbr = tag[0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "                \n",
    "    if tag_abbr in tag_dict:\n",
    "        return tag_dict[tag_abbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextMatrix(TransformerMixin):\n",
    "    \n",
    "    # initialize class & private variables\n",
    "    def __init__(self,\n",
    "                 window_size = 4,\n",
    "                 remove_stopwords = True,\n",
    "                 add_start_end_tokens = True,\n",
    "                 lowercase = False,\n",
    "                 lemmatize = False,\n",
    "                 pmi = False,\n",
    "                 spmi_k = 1,\n",
    "                 laplace_smoothing = 0,\n",
    "                 pmi_positive = False,\n",
    "                 sppmi_k = 1):\n",
    "        \n",
    "        \"\"\" Params:\n",
    "                window_size: size of +/- context window (default = 4)\n",
    "                remove_stopwords: boolean, whether or not to remove NLTK English stopwords\n",
    "                add_start_end_tokens: boolean, whether or not to append <START> and <END> to the\n",
    "                beginning/end of each document in the corpus (default = True)\n",
    "                lowercase: boolean, whether or not to convert words to all lowercase\n",
    "                lemmatize: boolean, whether or not to lemmatize input text\n",
    "                pmi: boolean, whether or not to compute pointwise mutual information\n",
    "                pmi_positive: boolean, whether or not to compute positive PMI\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.add_start_end_tokens = add_start_end_tokens\n",
    "        self.lowercase = lowercase\n",
    "        self.lemmatize = lemmatize\n",
    "        self.pmi = pmi\n",
    "        self.spmi_k = spmi_k\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "        self.pmi_positive = pmi_positive\n",
    "        self.sppmi_k = sppmi_k\n",
    "        self.corpus = None\n",
    "        self.clean_corpus = None\n",
    "        self.vocabulary = None\n",
    "        self.X = None\n",
    "        self.doc_terms_lists = None\n",
    "    \n",
    "    def fit(self, corpus, y = None):\n",
    "        \n",
    "        \"\"\" Learn the dictionary of all unique tokens for given corpus.\n",
    "        \n",
    "            Params:\n",
    "                corpus: list of strings\n",
    "            \n",
    "            Returns: self\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        term_dict = dict()\n",
    "        k = 0\n",
    "        corpus_words = []\n",
    "        clean_corpus = []\n",
    "        doc_terms_lists = []\n",
    "        detokenizer = TreebankWordDetokenizer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "            \n",
    "            # detokenize trick taken from this StackOverflow post:\n",
    "            # https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence\n",
    "            # and NLTK treebank documentation:\n",
    "            # https://www.nltk.org/_modules/nltk/tokenize/treebank.html\n",
    "            text = detokenizer.detokenize(words)\n",
    "            clean_corpus.append(text)\n",
    "            \n",
    "            [corpus_words.append(word) for word in words]\n",
    "            \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            doc_terms_lists.append(words)\n",
    "            \n",
    "        self.clean_corpus = clean_corpus\n",
    "        \n",
    "        self.doc_terms_lists = doc_terms_lists\n",
    "        \n",
    "        corpus_words = list(set(corpus_words))\n",
    "        \n",
    "        if self.add_start_end_tokens:\n",
    "            corpus_words = ['<START>'] + corpus_words + ['<END>']\n",
    "        \n",
    "        corpus_words = sorted(corpus_words)\n",
    "        \n",
    "        for el in corpus_words:\n",
    "            term_dict[el] = k\n",
    "            k += 1\n",
    "            \n",
    "        self.vocabulary = term_dict\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, new_corpus, y = None):\n",
    "        \n",
    "        \"\"\" Compute the co-occurrence matrix for given corpus and window_size, using term dictionary\n",
    "            obtained with fit method.\n",
    "        \n",
    "            Returns: term-context co-occurrence matrix (shape: target terms by context terms) with\n",
    "            raw counts\n",
    "        \"\"\"\n",
    "        num_terms = len(self.vocabulary)\n",
    "        window = self.window_size\n",
    "        X = np.full((num_terms, num_terms), self.laplace_smoothing)\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        if type(new_corpus) != list:\n",
    "            new_corpus = self.corpus\n",
    "        \n",
    "        for text in new_corpus:\n",
    "            text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "            \n",
    "            words = word_tokenize(text)\n",
    "            \n",
    "            if self.remove_stopwords:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    if word.lower() not in set(stopwords.words('english')):\n",
    "                        clean_words.append(word)\n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lowercase:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    clean_words.append(word.lower())\n",
    "                \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.lemmatize:\n",
    "                clean_words = []\n",
    "                for word in words:\n",
    "                    PoS_tag = pos_tag([word])[0][1]\n",
    "                    \n",
    "                    # to change contractions to full word form\n",
    "                    if word in contractions:\n",
    "                        word = contractions[word]\n",
    "\n",
    "                    if PoS_tag[0].upper() in 'JNVR':\n",
    "                        word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                    else:\n",
    "                        word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                    clean_words.append(word)\n",
    "                    \n",
    "                words = clean_words\n",
    "                \n",
    "            if self.add_start_end_tokens:\n",
    "                words = ['<START>'] + words + ['<END>']\n",
    "            \n",
    "            for i in range(len(words)):\n",
    "                target = words[i]\n",
    "                \n",
    "                # check to see if target word is in the dictionary; if not, skip\n",
    "                if target in self.vocabulary:\n",
    "                    \n",
    "                    # grab index from dictionary\n",
    "                    target_dict_index = self.vocabulary[target]\n",
    "                    \n",
    "                    # find left-most and right-most window indices for each target word\n",
    "                    left_end_index = max(i - window, 0)\n",
    "                    right_end_index = min(i + window, len(words) - 1)\n",
    "                    \n",
    "                    # loop over all words within window\n",
    "                    # NOTE: this will include the target word; make sure to skip over it\n",
    "                    for j in range(left_end_index, right_end_index + 1):\n",
    "                        \n",
    "                        # skip \"context word\" where the \"context word\" index is equal to the\n",
    "                        # target word index\n",
    "                        if j != i:\n",
    "                            context_word = words[j]\n",
    "                            \n",
    "                            # check to see if context word is in the fitted dictionary; if\n",
    "                            # not, skip\n",
    "                            if context_word in self.vocabulary:\n",
    "                                X[target_dict_index, self.vocabulary[context_word]] += 1\n",
    "        \n",
    "        # if pmi = True, compute pmi matrix from word-context raw frequencies\n",
    "        # more concise code taken from this StackOverflow post:\n",
    "        # https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus\n",
    "        if self.pmi:\n",
    "            denom = X.sum()\n",
    "            col_sums = X.sum(axis = 0)\n",
    "            row_sums = X.sum(axis = 1)\n",
    "            \n",
    "            expected = np.outer(row_sums, col_sums)/denom\n",
    "            \n",
    "            X = X/expected\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                \n",
    "                    if X[i,j] > 0:\n",
    "                        X[i,j] = np.log(X[i,j]) - np.log(self.spmi_k)\n",
    "                        \n",
    "                        if self.pmi_positive:\n",
    "                            X[i,j] = max(X[i,j] - np.log(self.sppmi_k), 0)\n",
    "        \n",
    "        # note that X is a dense matrix\n",
    "        self.X = X\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(lowercase = True, lemmatize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "    \"Coronavirus is a fake liberal hoax.\",\n",
    "    \"Trump won't do anything about coronavirus.\",\n",
    "    \"The liberal fake news media always blame Pres Trump.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ContextMatrix at 0x1a1b98de50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <th>always</th>\n",
       "      <th>anything</th>\n",
       "      <th>blame</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>fake</th>\n",
       "      <th>hoax</th>\n",
       "      <th>liberal</th>\n",
       "      <th>medium</th>\n",
       "      <th>news</th>\n",
       "      <th>pres</th>\n",
       "      <th>trump</th>\n",
       "      <th>wont</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;END&gt;</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;START&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronavirus</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoax</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .  <END>  <START>  always  anything  blame  coronavirus  fake  \\\n",
       ".            0      3        0       1         1      1            2     1   \n",
       "<END>        3      0        0       0         1      1            1     1   \n",
       "<START>      0      0        0       0         1      0            2     2   \n",
       "always       1      0        0       0         0      1            0     1   \n",
       "anything     1      1        1       0         0      0            1     0   \n",
       "blame        1      1        0       1         0      0            0     1   \n",
       "coronavirus  2      1        2       0         1      0            0     1   \n",
       "fake         1      1        2       1         0      1            1     0   \n",
       "hoax         1      1        1       0         0      0            1     1   \n",
       "liberal      1      1        2       1         0      0            1     2   \n",
       "medium       0      0        1       1         0      1            0     1   \n",
       "news         0      0        1       1         0      1            0     1   \n",
       "pres         1      1        0       1         0      1            0     0   \n",
       "trump        2      1        1       1         1      1            1     0   \n",
       "wont         1      1        1       0         1      0            1     0   \n",
       "\n",
       "             hoax  liberal  medium  news  pres  trump  wont  \n",
       ".               1        1       0     0     1      2     1  \n",
       "<END>           1        1       0     0     1      1     1  \n",
       "<START>         1        2       1     1     0      1     1  \n",
       "always          0        1       1     1     1      1     0  \n",
       "anything        0        0       0     0     0      1     1  \n",
       "blame           0        0       1     1     1      1     0  \n",
       "coronavirus     1        1       0     0     0      1     1  \n",
       "fake            1        2       1     1     0      0     0  \n",
       "hoax            0        1       0     0     0      0     0  \n",
       "liberal         1        0       1     1     0      0     0  \n",
       "medium          0        1       0     1     1      1     0  \n",
       "news            0        1       1     0     1      0     0  \n",
       "pres            0        0       1     1     0      1     0  \n",
       "trump           0        0       1     0     1      0     1  \n",
       "wont            0        0       0     0     0      1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm.transform(tweets), index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus fake liberal hoax.',\n",
       " 'trump wont anything coronavirus.',\n",
       " 'liberal fake news medium always blame pres trump.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coronavirus is a fake liberal hoax.',\n",
       " \"Trump won't do anything about coronavirus.\",\n",
       " 'The liberal fake news media always blame Pres Trump.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train embeddings using tweets as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 3, 6, 9</td>\n",
       "      <td>We are living in scary times in Canada. Gov’t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 6, 8, 9</td>\n",
       "      <td>Just as bad in Canada. In fact, our government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1, 4, 9</td>\n",
       "      <td>It was only a matter of time before the mainst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8</td>\n",
       "      <td>Russia's taking no chances: Foreigners infecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6, 8, 9</td>\n",
       "      <td>Although there is now a presumptive confirmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable    Category  \\\n",
       "0                1  1, 3, 6, 9   \n",
       "1                1  1, 6, 8, 9   \n",
       "2                1     1, 4, 9   \n",
       "3                1        6, 8   \n",
       "4                1     6, 8, 9   \n",
       "..             ...         ...   \n",
       "555              0         NaN   \n",
       "556              0         NaN   \n",
       "557              0         NaN   \n",
       "558              0         NaN   \n",
       "559              0         NaN   \n",
       "\n",
       "                                                 Tweet  \n",
       "0    We are living in scary times in Canada. Gov’t ...  \n",
       "1    Just as bad in Canada. In fact, our government...  \n",
       "2    It was only a matter of time before the mainst...  \n",
       "3    Russia's taking no chances: Foreigners infecte...  \n",
       "4    Although there is now a presumptive confirmed ...  \n",
       "..                                                 ...  \n",
       "555  BREAKING: Harvard classes will move online sta...  \n",
       "556  Singularity University is hosting a FREE Virtu...  \n",
       "557  Coronavirus: how does it spread and what are t...  \n",
       "558  Stanford just cancelled classes for the rest o...  \n",
       "559  Tech conferences were cancelled in #Waterloo R...  \n",
       "\n",
       "[560 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create outlier target values\n",
    "outlier = []\n",
    "for i in tweets['Is_Unreliable']:\n",
    "    if i == 0:\n",
    "        i = 1\n",
    "    else:\n",
    "        i = -1\n",
    "    outlier.append(i)\n",
    "tweets['outlier_target'] = outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Unreliable</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>outlier_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus is spreading wild wide and cities ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This morning, Sunnybrook discharged home the p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This afternoon, @WHO declared #coronavirus a p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinese health authorities announced Sunday th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local communities band together to show their ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BREAKING: Harvard classes will move online sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singularity University is hosting a FREE Virtu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus: how does it spread and what are t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanford just cancelled classes for the rest o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tech conferences were cancelled in #Waterloo R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Is_Unreliable Category  \\\n",
       "280              0      NaN   \n",
       "281              0      NaN   \n",
       "282              0      NaN   \n",
       "283              0      NaN   \n",
       "284              0      NaN   \n",
       "..             ...      ...   \n",
       "555              0      NaN   \n",
       "556              0      NaN   \n",
       "557              0      NaN   \n",
       "558              0      NaN   \n",
       "559              0      NaN   \n",
       "\n",
       "                                                 Tweet  outlier_target  \n",
       "280  Coronavirus is spreading wild wide and cities ...               1  \n",
       "281  This morning, Sunnybrook discharged home the p...               1  \n",
       "282  This afternoon, @WHO declared #coronavirus a p...               1  \n",
       "283  Chinese health authorities announced Sunday th...               1  \n",
       "284  Local communities band together to show their ...               1  \n",
       "..                                                 ...             ...  \n",
       "555  BREAKING: Harvard classes will move online sta...               1  \n",
       "556  Singularity University is hosting a FREE Virtu...               1  \n",
       "557  Coronavirus: how does it spread and what are t...               1  \n",
       "558  Stanford just cancelled classes for the rest o...               1  \n",
       "559  Tech conferences were cancelled in #Waterloo R...               1  \n",
       "\n",
       "[280 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reliable_tweets = tweets[tweets['outlier_target'] == 1]\n",
    "reliable_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ContextMatrix(window_size = 15, lowercase = True, lemmatize = True, pmi = True, laplace_smoothing = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_matrix = cm.fit_transform(reliable_tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>#</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>,</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yet</th>\n",
       "      <th>yokohama</th>\n",
       "      <th>york</th>\n",
       "      <th>yorku</th>\n",
       "      <th>zone</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>—</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>2.697417</td>\n",
       "      <td>-0.277508</td>\n",
       "      <td>-0.357348</td>\n",
       "      <td>0.333142</td>\n",
       "      <td>0.071339</td>\n",
       "      <td>0.798775</td>\n",
       "      <td>-0.133872</td>\n",
       "      <td>0.683422</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>-0.141331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.120471</td>\n",
       "      <td>-0.118783</td>\n",
       "      <td>-0.225241</td>\n",
       "      <td>-0.122156</td>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.110301</td>\n",
       "      <td>-0.119628</td>\n",
       "      <td>-0.114551</td>\n",
       "      <td>1.583916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.277508</td>\n",
       "      <td>3.468590</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.708120</td>\n",
       "      <td>1.755651</td>\n",
       "      <td>0.968959</td>\n",
       "      <td>0.123324</td>\n",
       "      <td>2.550056</td>\n",
       "      <td>-1.248726</td>\n",
       "      <td>-0.577283</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.244498</td>\n",
       "      <td>-1.249570</td>\n",
       "      <td>-1.247882</td>\n",
       "      <td>0.842885</td>\n",
       "      <td>-0.152642</td>\n",
       "      <td>-0.551351</td>\n",
       "      <td>-1.239400</td>\n",
       "      <td>-0.555579</td>\n",
       "      <td>-1.243650</td>\n",
       "      <td>1.504639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.357348</td>\n",
       "      <td>0.710778</td>\n",
       "      <td>0.630939</td>\n",
       "      <td>2.707722</td>\n",
       "      <td>1.164986</td>\n",
       "      <td>-0.410163</td>\n",
       "      <td>-0.244197</td>\n",
       "      <td>0.727247</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.251657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.230797</td>\n",
       "      <td>-0.229109</td>\n",
       "      <td>-0.335567</td>\n",
       "      <td>-0.232482</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.220627</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>0.220827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>0.333142</td>\n",
       "      <td>0.708120</td>\n",
       "      <td>2.707722</td>\n",
       "      <td>0.625623</td>\n",
       "      <td>1.162328</td>\n",
       "      <td>-0.412821</td>\n",
       "      <td>-0.246855</td>\n",
       "      <td>0.724589</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.254315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.233455</td>\n",
       "      <td>-0.231767</td>\n",
       "      <td>-0.338225</td>\n",
       "      <td>-0.235140</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.223285</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.227535</td>\n",
       "      <td>0.218169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.071339</td>\n",
       "      <td>1.755651</td>\n",
       "      <td>1.164986</td>\n",
       "      <td>1.162328</td>\n",
       "      <td>2.042623</td>\n",
       "      <td>0.529349</td>\n",
       "      <td>0.472171</td>\n",
       "      <td>2.003232</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>0.177030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.900722</td>\n",
       "      <td>-0.205888</td>\n",
       "      <td>0.380802</td>\n",
       "      <td>0.196205</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.890553</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>-0.201656</td>\n",
       "      <td>1.160339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>-0.115399</td>\n",
       "      <td>-0.551351</td>\n",
       "      <td>-0.225725</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.202503</td>\n",
       "      <td>-0.168214</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.283567</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>-0.009708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>-0.093618</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>-0.230372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>-0.110301</td>\n",
       "      <td>-1.239400</td>\n",
       "      <td>-0.220627</td>\n",
       "      <td>-0.223285</td>\n",
       "      <td>-0.890553</td>\n",
       "      <td>-0.163117</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-0.971617</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>-0.004611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>-0.088521</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>-0.225274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>-0.119628</td>\n",
       "      <td>-0.555579</td>\n",
       "      <td>-0.229953</td>\n",
       "      <td>-0.232611</td>\n",
       "      <td>-0.206732</td>\n",
       "      <td>-0.172443</td>\n",
       "      <td>-0.006477</td>\n",
       "      <td>-0.287795</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>-0.013937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>-0.097847</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>-0.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>-0.114551</td>\n",
       "      <td>-1.243650</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>-0.227535</td>\n",
       "      <td>-0.201656</td>\n",
       "      <td>-0.167367</td>\n",
       "      <td>-0.001401</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>-0.008861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.013687</td>\n",
       "      <td>-0.092771</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>0.463623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>1.583916</td>\n",
       "      <td>1.504639</td>\n",
       "      <td>0.220827</td>\n",
       "      <td>0.218169</td>\n",
       "      <td>1.160339</td>\n",
       "      <td>0.683803</td>\n",
       "      <td>-0.248844</td>\n",
       "      <td>1.341640</td>\n",
       "      <td>0.864012</td>\n",
       "      <td>-0.256304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868241</td>\n",
       "      <td>-0.235443</td>\n",
       "      <td>-0.233756</td>\n",
       "      <td>-0.340214</td>\n",
       "      <td>-0.237128</td>\n",
       "      <td>-0.230372</td>\n",
       "      <td>-0.225274</td>\n",
       "      <td>-0.234600</td>\n",
       "      <td>0.463623</td>\n",
       "      <td>1.132471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 1164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   !         #         (         )         ,         -  \\\n",
       "!           2.697417 -0.277508 -0.357348  0.333142  0.071339  0.798775   \n",
       "#          -0.277508  3.468590  0.710778  0.708120  1.755651  0.968959   \n",
       "(          -0.357348  0.710778  0.630939  2.707722  1.164986 -0.410163   \n",
       ")           0.333142  0.708120  2.707722  0.625623  1.162328 -0.412821   \n",
       ",           0.071339  1.755651  1.164986  1.162328  2.042623  0.529349   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "zone       -0.115399 -0.551351 -0.225725 -0.228383 -0.202503 -0.168214   \n",
       "zuckerberg -0.110301 -1.239400 -0.220627 -0.223285 -0.890553 -0.163117   \n",
       "—          -0.119628 -0.555579 -0.229953 -0.232611 -0.206732 -0.172443   \n",
       "‘          -0.114551 -1.243650 -0.224877 -0.227535 -0.201656 -0.167367   \n",
       "’           1.583916  1.504639  0.220827  0.218169  1.160339  0.683803   \n",
       "\n",
       "                  --         .       ...         1  ...      yeah       yet  \\\n",
       "!          -0.133872  0.683422  1.266667 -0.141331  ... -0.115399 -0.120471   \n",
       "#           0.123324  2.550056 -1.248726 -0.577283  ... -1.244498 -1.249570   \n",
       "(          -0.244197  0.727247 -0.229953 -0.251657  ... -0.225725 -0.230797   \n",
       ")          -0.246855  0.724589 -0.232611 -0.254315  ... -0.228383 -0.233455   \n",
       ",           0.472171  2.003232 -0.206732  0.177030  ... -0.202503 -0.900722   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "zone       -0.002249 -0.283567  0.011995 -0.009708  ...  0.016224  0.011152   \n",
       "zuckerberg  0.002849 -0.971617  0.017093 -0.004611  ...  0.021321  0.016249   \n",
       "—          -0.006477 -0.287795  0.007767 -0.013937  ...  0.011995  0.006923   \n",
       "‘          -0.001401 -0.975866  0.012843 -0.008861  ...  0.017071  0.012000   \n",
       "’          -0.248844  1.341640  0.864012 -0.256304  ...  0.868241 -0.235443   \n",
       "\n",
       "            yokohama      york     yorku      zone  zuckerberg         —  \\\n",
       "!          -0.118783 -0.225241 -0.122156 -0.115399   -0.110301 -0.119628   \n",
       "#          -1.247882  0.842885 -0.152642 -0.551351   -1.239400 -0.555579   \n",
       "(          -0.229109 -0.335567 -0.232482 -0.225725   -0.220627 -0.229953   \n",
       ")          -0.231767 -0.338225 -0.235140 -0.228383   -0.223285 -0.232611   \n",
       ",          -0.205888  0.380802  0.196205 -0.202503   -0.890553 -0.206732   \n",
       "...              ...       ...       ...       ...         ...       ...   \n",
       "zone        0.012840 -0.093618  0.009467  0.016224    0.021321  0.011995   \n",
       "zuckerberg  0.017937 -0.088521  0.014565  0.021321    0.026419  0.017093   \n",
       "—           0.008611 -0.097847  0.005238  0.011995    0.017093  0.007767   \n",
       "‘           0.013687 -0.092771  0.010315  0.017071    0.022169  0.012843   \n",
       "’          -0.233756 -0.340214 -0.237128 -0.230372   -0.225274 -0.234600   \n",
       "\n",
       "                   ‘         ’  \n",
       "!          -0.114551  1.583916  \n",
       "#          -1.243650  1.504639  \n",
       "(          -0.224877  0.220827  \n",
       ")          -0.227535  0.218169  \n",
       ",          -0.201656  1.160339  \n",
       "...              ...       ...  \n",
       "zone        0.017071 -0.230372  \n",
       "zuckerberg  0.022169 -0.225274  \n",
       "—           0.012843 -0.234600  \n",
       "‘           0.017919  0.463623  \n",
       "’           0.463623  1.132471  \n",
       "\n",
       "[1164 rows x 1164 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_context_matrix, index = cm.vocabulary, columns = cm.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164, 1164)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components = 2)\n",
    "std_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0316529 , -0.02036111],\n",
       "       [-0.54067734,  0.6613883 ],\n",
       "       [-0.06467443, -0.07540193],\n",
       "       ...,\n",
       "       [ 0.00380218,  0.00528292],\n",
       "       [ 0.00883194, -0.00180905],\n",
       "       [-0.07683285, -0.00580801]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = std_scaler.fit_transform(word_context_matrix)\n",
    "\n",
    "matrix = ica.fit_transform(X_std)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comp 1</th>\n",
       "      <th>Comp 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>-0.031653</td>\n",
       "      <td>-0.020361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-0.540677</td>\n",
       "      <td>0.661388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-0.064674</td>\n",
       "      <td>-0.075402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>-0.064530</td>\n",
       "      <td>-0.077474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.202605</td>\n",
       "      <td>-0.342612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.003552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg</th>\n",
       "      <td>0.009196</td>\n",
       "      <td>0.003103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.005283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‘</th>\n",
       "      <td>0.008832</td>\n",
       "      <td>-0.001809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>-0.076833</td>\n",
       "      <td>-0.005808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Comp 1    Comp 2\n",
       "!          -0.031653 -0.020361\n",
       "#          -0.540677  0.661388\n",
       "(          -0.064674 -0.075402\n",
       ")          -0.064530 -0.077474\n",
       ",          -0.202605 -0.342612\n",
       "...              ...       ...\n",
       "zone        0.005972  0.003552\n",
       "zuckerberg  0.009196  0.003103\n",
       "—           0.003802  0.005283\n",
       "‘           0.008832 -0.001809\n",
       "’          -0.076833 -0.005808\n",
       "\n",
       "[1164 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  index = cm.vocabulary,\n",
    "                  columns = ['Comp {}'.format(i+1) for i in range(2)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/caitlinmoroney/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [key for key in cm.vocabulary.keys()]\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    \n",
    "    #if re.match('^co[rv]', word):\n",
    "    \n",
    "        x = df['Comp 1'][i]\n",
    "        y = df['Comp 2'][i]\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.text(x, y, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set word embeddings for text classification\n",
    "ica = FastICA(n_components = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00618275, -0.00748204,  0.00576863, ...,  0.0131414 ,\n",
       "         0.00257713,  0.00245221],\n",
       "       [ 0.00088404,  0.01744919, -0.01363817, ..., -0.00877908,\n",
       "        -0.00749502,  0.01169456],\n",
       "       [-0.00380684,  0.01374158,  0.0018952 , ..., -0.00754247,\n",
       "         0.00321619,  0.00036462],\n",
       "       ...,\n",
       "       [-0.01007283, -0.00682459, -0.00749961, ...,  0.00641914,\n",
       "        -0.01310977, -0.00199204],\n",
       "       [-0.01182981, -0.00503676, -0.02466672, ..., -0.00256948,\n",
       "         0.00157315, -0.01284545],\n",
       "       [-0.0118071 ,  0.010433  ,  0.071797  , ..., -0.02127344,\n",
       "         0.09309713,  0.01597378]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ica.fit_transform(X_std)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out target\n",
    "y = tweets['outlier_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive text vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vectors(word_embeddings,\n",
    "                     word_index_dict,\n",
    "                     text_list,\n",
    "                     remove_stopwords = True,\n",
    "                     lowercase = True,\n",
    "                     lemmatize = True,\n",
    "                     add_start_end_tokens = True):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for k in range(len(text_list)):\n",
    "        text = text_list[k]\n",
    "        text = re.sub(r'[_~`@$%^&*[\\]+=\\|}{\\\"\\'<>/]+', '', text)\n",
    "        text_vec = np.zeros(word_embeddings.shape[1])\n",
    "        words = word_tokenize(text)\n",
    "        tracker = 0 # to track whether we've encountered a word for which we have an embedding (in each tweet)\n",
    "        \n",
    "        if remove_stopwords:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                if word.lower() not in set(stopwords.words('english')):\n",
    "                    clean_words.append(word)\n",
    "            words = clean_words\n",
    "\n",
    "        if lowercase:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                clean_words.append(word.lower())\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if lemmatize:\n",
    "            clean_words = []\n",
    "            for word in words:\n",
    "                PoS_tag = pos_tag([word])[0][1]\n",
    "\n",
    "                # to change contractions to full word form\n",
    "                if word in contractions:\n",
    "                    word = contractions[word]\n",
    "\n",
    "                if PoS_tag[0].upper() in 'JNVR':\n",
    "                    word = lemmatizer.lemmatize(word, convert_pos_wordnet(PoS_tag))\n",
    "                else:\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "\n",
    "                clean_words.append(word)\n",
    "\n",
    "            words = clean_words\n",
    "\n",
    "        if add_start_end_tokens:\n",
    "            words = ['<START>'] + words + ['<END>']\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            word = words[i]\n",
    "            if word in word_index_dict:\n",
    "                word_embed_vec = word_embeddings[word_index_dict[word],:]\n",
    "                if tracker == 0:\n",
    "                    text_matrix = word_embed_vec\n",
    "                else:\n",
    "                    text_matrix = np.vstack((text_matrix, word_embed_vec))\n",
    "                    \n",
    "                # only increment if we have come across a word in the embeddings dictionary\n",
    "                tracker += 1\n",
    "                    \n",
    "        for j in range(len(text_vec)):\n",
    "            text_vec[j] = text_matrix[:,j].mean()\n",
    "            \n",
    "        if k == 0:\n",
    "            full_matrix = text_vec\n",
    "        else:\n",
    "            full_matrix = np.vstack((full_matrix, text_vec))\n",
    "            \n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_text_vectors(embeddings, cm.vocabulary, tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.00260534e-04,  2.66046610e-02,  4.92052453e-03, ...,\n",
       "         6.65975934e-04,  1.60407042e-02, -6.83851577e-04],\n",
       "       [-1.44894217e-03,  1.03631706e-02, -1.10819994e-03, ...,\n",
       "         7.78653807e-03,  1.35825253e-03, -2.95937623e-03],\n",
       "       [ 7.21841870e-04,  1.63711189e-03, -4.42575537e-03, ...,\n",
       "         4.40879695e-03, -3.33377929e-03, -3.78404074e-03],\n",
       "       ...,\n",
       "       [-3.73492635e-04, -2.69556982e-03,  3.16004208e-03, ...,\n",
       "        -3.09721058e-03,  3.61906980e-03, -2.03950165e-03],\n",
       "       [-4.77928105e-04, -8.74811036e-03,  2.11252590e-01, ...,\n",
       "         3.03231068e-03,  1.37662394e-04, -6.17784955e-03],\n",
       "       [ 9.49057797e-03, -6.98805859e-04,  7.92726481e-03, ...,\n",
       "         3.95777203e-03, -6.62429307e-03, -1.45780208e-03]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_fraction = 0.10\n",
    "Nsamples_unreliable = int(np.round(280/(1-resample_fraction)*resample_fraction))\n",
    "\n",
    "resample_dict = {\n",
    "    -1: Nsamples_unreliable,\n",
    "    1: 280\n",
    "}\n",
    "\n",
    "underSample = RandomUnderSampler(sampling_strategy = resample_dict,\n",
    "                                 random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imb, y_imb = underSample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('classify', OneClassSVM(nu = resample_fraction))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparams to optimize\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "\n",
    "# set up parameter grid\n",
    "params = {\n",
    "    'classify__kernel': kernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CV scheme for inner and outer loops\n",
    "inner_cv = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "# Set up GridSearch for inner loop\n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv, scoring = 'f1_macro')\n",
    "\n",
    "# Nested CV scores\n",
    "scores = cross_validate(grid_SVC,\n",
    "                        X = X_imb,\n",
    "                        y = y_imb,\n",
    "                        cv = outer_cv,\n",
    "                        scoring = ['roc_auc', 'accuracy', 'f1_macro', 'precision_macro', 'recall_macro'],\n",
    "                        return_estimator = True,\n",
    "                        return_train_score = True)\n",
    "\n",
    "test_auc = scores['test_roc_auc']\n",
    "train_auc = scores['train_roc_auc']\n",
    "\n",
    "test_accuracy = scores['test_accuracy']\n",
    "train_accuracy = scores['train_accuracy']\n",
    "\n",
    "test_f1 = scores['test_f1_macro']\n",
    "train_f1 = scores['train_f1_macro']\n",
    "\n",
    "test_precision = scores['test_precision_macro']\n",
    "train_precision = scores['train_precision_macro']\n",
    "\n",
    "test_recall = scores['test_recall_macro']\n",
    "train_recall = scores['train_recall_macro']\n",
    "\n",
    "estimators = scores['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27797619047619043"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266769073220687"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46336889167744894"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4823107448107448"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4607142857142857"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'rbf'}\n",
      "\n",
      "\n",
      "{'classify__kernel': 'sigmoid'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in estimators:\n",
    "    print(i.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
